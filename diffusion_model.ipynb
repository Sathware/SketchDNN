{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from config import NODE_FEATURE_DIMENSION, EDGE_FEATURE_DIMENSION, MAX_NUM_PRIMITIVES, GRAPH_EMBEDDING_SIZE\n",
    "from matplotlib import pyplot as plt\n",
    "from dataset1 import SketchDataset\n",
    "import os\n",
    "os.chdir('SketchGraphs/')\n",
    "import sketchgraphs.data as datalib\n",
    "os.chdir('../')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "class GD3PM(nn.Module):\n",
    "  def __init__(self, device : torch.device):\n",
    "    super().__init__()\n",
    "    self.device = device\n",
    "    self.node_dim = NODE_FEATURE_DIMENSION\n",
    "    self.edge_dim = EDGE_FEATURE_DIMENSION\n",
    "    self.hidden_dim = 256\n",
    "    self.num_tf_layers = 24\n",
    "    self.num_heads = 16\n",
    "    self.max_timestep = 500\n",
    "    self.max_steps = self.max_timestep + 1\n",
    "    self.noise_scheduler = CosineNoiseScheduler(self.max_timestep, self.device)\n",
    "    self.time_embedder = TimeEmbedder(self.max_timestep, self.hidden_dim, self.device)\n",
    "    self.mlp_in_nodes = nn.Sequential(nn.Linear(in_features = self.node_dim, out_features = self.hidden_dim, device = device),\n",
    "                                            nn.LeakyReLU(.1),\n",
    "                                            # nn.Dropout(p = 0.1),\n",
    "                                            nn.Linear(in_features = self.hidden_dim, out_features = self.hidden_dim, device = device),\n",
    "                                            nn.LeakyReLU(.1),\n",
    "                                            # nn.Dropout(p = 0.1)\n",
    "                                           )\n",
    "    self.mlp_in_edges = nn.Sequential(nn.Linear(in_features = self.edge_dim, out_features = self.hidden_dim, device = device),\n",
    "                                            nn.LeakyReLU(.1),\n",
    "                                            # nn.Dropout(p = 0.1),\n",
    "                                            nn.Linear(in_features = self.hidden_dim, out_features = self.hidden_dim, device = device),\n",
    "                                            nn.LeakyReLU(.1),\n",
    "                                            # nn.Dropout(p = 0.1)\n",
    "                                           )\n",
    "    self.tf_layers = nn.ModuleList([TransformerLayer(num_heads = self.num_heads,\n",
    "                                                     node_dim = self.hidden_dim,\n",
    "                                                     edge_dim = self.hidden_dim,\n",
    "                                                     device = device\n",
    "                                                    )\n",
    "                                    for _ in range(self.num_tf_layers)])\n",
    "    self.mlp_out_nodes = nn.Sequential(nn.Linear(in_features = self.hidden_dim, out_features = self.node_dim, device = device),\n",
    "                                       nn.LeakyReLU(.1),\n",
    "                                    #    nn.Dropout(p = 0.1),\n",
    "                                       nn.Linear(in_features = self.node_dim, out_features = self.node_dim, device = device)\n",
    "                                      )\n",
    "    self.mlp_out_edges = nn.Sequential(nn.Linear(in_features = self.hidden_dim, out_features = self.edge_dim, device = device),\n",
    "                                       nn.LeakyReLU(.1),\n",
    "                                    #    nn.Dropout(p = 0.1),\n",
    "                                       nn.Linear(in_features = self.edge_dim, out_features = self.edge_dim, device = device)\n",
    "                                      )\n",
    "\n",
    "  def forward(self, nodes : Tensor, edges : Tensor, timestep : Tensor):\n",
    "    # embed timestep\n",
    "    time_embs = self.time_embedder(timestep) # batch_size x hidden_dim\n",
    "    nodes = self.mlp_in_nodes(nodes) # batch_size x num_nodes x hidden_dim\n",
    "    edges = self.mlp_in_edges(edges) # batch_size x num_nodes x num_nodes x hidden_dim\n",
    "    for idx, layer in enumerate(self.tf_layers):\n",
    "      nodes, edges, time_embs = layer(nodes, edges, time_embs) if idx % 12 == 0 else checkpoint(layer, nodes, edges, time_embs, use_reentrant = False)\n",
    "    nodes = self.mlp_out_nodes(nodes)\n",
    "    edges = self.mlp_out_edges(edges)\n",
    "    return nodes, edges\n",
    "  \n",
    "  @torch.no_grad()\n",
    "  def sample(self, batch_size : int):\n",
    "    # Sample Noise\n",
    "    num_nodes = MAX_NUM_PRIMITIVES\n",
    "    num_node_features = NODE_FEATURE_DIMENSION\n",
    "    num_edge_features = EDGE_FEATURE_DIMENSION\n",
    "    nodes = torch.zeros(batch_size, num_nodes, num_node_features)\n",
    "    edges = torch.zeros(batch_size, num_nodes, num_nodes, num_edge_features)\n",
    "    # binary noise (isConstructible)\n",
    "    nodes[:,:,0] = torch.ones(size = (batch_size * num_nodes, 2)).multinomial(1)\\\n",
    "                        .reshape(batch_size, num_nodes).float()\n",
    "    # categorical noise (primitive type)\n",
    "    nodes[:,:,1:6] = F.one_hot(torch.ones(size = (batch_size * num_nodes, 5)).multinomial(1), 5)\\\n",
    "                      .reshape(batch_size, num_nodes, -1).float()\n",
    "    # gaussian noise (primitive parameters)\n",
    "    nodes[:,:,6:] = torch.randn(size = (batch_size, num_nodes, 14))\n",
    "    # categorical noise (subnode a type)\n",
    "    edges[:,:,:,0:4] = F.one_hot(torch.ones(size = (batch_size * num_nodes * num_nodes, 4)).multinomial(1), 4)\\\n",
    "                      .reshape(batch_size, num_nodes, num_nodes, -1).float()\n",
    "    # categorical noise (subnode b type)\n",
    "    edges[:,:,:,4:8] = F.one_hot(torch.ones(size = (batch_size * num_nodes * num_nodes, 4)).multinomial(1), 4)\\\n",
    "                      .reshape(batch_size, num_nodes, num_nodes, -1).float()\n",
    "    # categorical noise (subnode a type)\n",
    "    edges[:,:,:,8:] = F.one_hot(torch.ones(size = (batch_size * num_nodes * num_nodes, 9)).multinomial(1), 9)\\\n",
    "                     .reshape(batch_size, num_nodes, num_nodes, -1).float()\n",
    "    \n",
    "    nodes = nodes.to(self.device)\n",
    "    edges = edges.to(self.device)\n",
    "    return self.denoise(nodes, edges)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def denoise(self, nodes, edges):\n",
    "    for t in reversed(range(1, self.max_steps)):\n",
    "      # model expects a timestep for each batch\n",
    "      batch_size = nodes.size(0)\n",
    "      time = torch.Tensor([t]).expand(batch_size).int() # batch size of 1\n",
    "      pred_node_noise, pred_edge_noise = self.forward(nodes, edges, time)\n",
    "      # Normalize output into probabilities\n",
    "      pred_node_noise[:,:,0] = F.sigmoid(input = pred_node_noise[:,:,0])\n",
    "      pred_node_noise[:,:,1:6] = F.softmax(input = pred_node_noise[:,:,1:6], dim = 2)\n",
    "      pred_edge_noise[:,:,:,0:4] = F.softmax(input = pred_edge_noise[:,:,:,0:4], dim = 3)\n",
    "      pred_edge_noise[:,:,:,4:8] = F.softmax(input = pred_edge_noise[:,:,:,4:8], dim = 3)\n",
    "      pred_edge_noise[:,:,:,8:] = F.softmax(input = pred_edge_noise[:,:,:,8:], dim = 3)\n",
    "\n",
    "      nodes, edges = self.reverse_step(nodes, edges, pred_node_noise, pred_edge_noise, t)\n",
    "    return nodes, edges\n",
    "  @torch.no_grad()\n",
    "  def noise(self, nodes, edges):\n",
    "    nodes, edges, _ = self.noise_scheduler(nodes, edges, self.max_timestep)\n",
    "    return nodes, edges\n",
    "  \n",
    "  @torch.no_grad()\n",
    "  def reverse_step(self, nodes, edges, pred_node_noise, pred_edge_noise, timestep):\n",
    "    # IsConstructible denoising\n",
    "    nodes[:,:,0] = self.noise_scheduler.apply_bernoulli_posterior_step(nodes[:,:,0], pred_node_noise[:,:,0], timestep)\n",
    "    # Primitive Types denoising\n",
    "    nodes[:,:,1:6] = self.noise_scheduler.apply_multinomial_posterior_step(nodes[:,:,1:6], pred_node_noise[:,:,1:6], timestep)\n",
    "    # Primitive parameters denoising\n",
    "    nodes[:,:,6:] = self.noise_scheduler.apply_gaussian_posterior_step(nodes[:,:,6:], pred_node_noise[:,:,6:], timestep)\n",
    "    # Subnode A denoising\n",
    "    edges[:,:,:,0:4] = self.noise_scheduler.apply_multinomial_posterior_step(edges[:,:,:,0:4], pred_edge_noise[:,:,:,0:4], timestep)\n",
    "    # Subnode B denoising\n",
    "    edges[:,:,:,4:8] = self.noise_scheduler.apply_multinomial_posterior_step(edges[:,:,:,4:8], pred_edge_noise[:,:,:,4:8], timestep)\n",
    "    # Constraint Types denoising\n",
    "    edges[:,:,:,8:] = self.noise_scheduler.apply_multinomial_posterior_step(edges[:,:,:,8:], pred_edge_noise[:,:,:,8:], timestep)\n",
    "    return nodes, edges\n",
    "  \n",
    "  # @torch.no_grad()\n",
    "  # def forward_step(self, nodes, edges, timestep):\n",
    "  #   bool_class_probs = torch.cat(((1 - nodes[:,:,0]).unsqueeze(-1), nodes[:,:,0].unsqueeze(-1)), dim = -1) # batch_size x num_nodes x 2 i.e. [p(fail), p(success)]\n",
    "  #   nodes[:,:,0] = (bool_class_probs @ self.noise_scheduler.get_transition_matrix(2, timestep)).reshape(-1, 2).multinomial(1).reshape(nodes[:,:,0].size()).float()\n",
    "  #   # Primitive Types noising\n",
    "  #   nodes[:,:,1:6] = self.noise_scheduler.sample_discrete(nodes[:,:,1:6] @ self.noise_scheduler.get_transition_matrix(5, timestep)).float()\n",
    "  #   # Primitive parameters noising\n",
    "  #   nodes[:,:,6:] = self.noise_scheduler.get_transition_noise(nodes[:,:,6:], timestep)\n",
    "  #   # Subnode A noising\n",
    "  #   edges[:,:,:,0:4] = self.noise_scheduler.sample_discrete(edges[:,:,:,0:4] @ self.noise_scheduler.get_transition_matrix(4, timestep)).float()\n",
    "  #   # Subnode B noising\n",
    "  #   edges[:,:,:,4:8] = self.noise_scheduler.sample_discrete(edges[:,:,:,4:8] @ self.noise_scheduler.get_transition_matrix(4, timestep)).float()\n",
    "  #   # Constraint Types noising\n",
    "  #   edges[:,:,:,8:] = self.noise_scheduler.sample_discrete(edges[:,:,:,8:] @ self.noise_scheduler.get_transition_matrix(9, timestep)).float()\n",
    "  #   return nodes, edges\n",
    "\n",
    "class TimeEmbedder(nn.Module):\n",
    "  def __init__(self, max_timestep : int, embedding_dimension : int, device : torch.device):\n",
    "    super().__init__()\n",
    "    self.device = device\n",
    "    self.embed_dim = embedding_dimension\n",
    "    self.max_steps = max_timestep + 1\n",
    "    self.max_timestep = max_timestep\n",
    "      \n",
    "    timesteps = torch.arange(self.max_steps, device = self.device).unsqueeze(1) # num_timesteps x 1\n",
    "    scales = torch.exp(torch.arange(0, self.embed_dim, 2, device = self.device) * (-math.log(10000.0) / self.embed_dim)).unsqueeze(0) # 1 x (embedding_dimension // 2)\n",
    "    self.time_embs = torch.zeros(self.max_steps, self.embed_dim, device = self.device) # num_timesteps x embedding_dimension\n",
    "    self.time_embs[:, 0::2] = torch.sin(timesteps * scales) # fill even columns with sin(timestep * 1000^-(2*i/embedding_dimension))\n",
    "    self.time_embs[:, 1::2] = torch.cos(timesteps * scales) # fill odd columns with cos(timestep * 1000^-(2*i/embedding_dimension))\n",
    "      \n",
    "  def forward(self, timestep : Tensor):\n",
    "    return self.time_embs[timestep] # batch_size x embedding_dimension\n",
    "\n",
    "class CosineNoiseScheduler(nn.Module):\n",
    "    def __init__(self, max_timestep : int, device : torch.device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.max_steps = max_timestep + 1\n",
    "        self.max_timestep = max_timestep\n",
    "        self.offset = .008 # Fixed offset to improve noise prediction at early timesteps\n",
    "        # Cosine Beta Schedule Formula: https://arxiv.org/abs/2102.09672     1.00015543316 is 1/a(0), for offset = .008\n",
    "        self.cumulative_precisions = torch.cos((torch.linspace(0, 1, self.max_steps).to(self.device) + self.offset) * 0.5 * math.pi / (1 + self.offset)) ** 2 * 1.00015543316\n",
    "        self.cumulative_variances = 1 - self.cumulative_precisions\n",
    "        self.variances = torch.cat([torch.Tensor([0]).to(self.device), 1 - (self.cumulative_precisions[1:] / self.cumulative_precisions[:-1])]).clamp(.0001, .9999)\n",
    "        self.precisions = 1 - self.variances\n",
    "        self.sqrt_cumulative_precisions = torch.sqrt(self.cumulative_precisions)\n",
    "        self.sqrt_cumulative_variances = torch.sqrt(self.cumulative_variances)\n",
    "        self.sqrt_precisions = torch.sqrt(self.precisions)\n",
    "        self.sqrt_variances = torch.sqrt(self.variances)\n",
    "        self.sqrt_posterior_variances = torch.cat([torch.Tensor([0]).to(self.device), torch.sqrt(self.variances[1:] * self.cumulative_variances[:-1] / self.cumulative_variances[1:])])\n",
    "\n",
    "    def forward(self, nodes : Tensor, edges : Tensor, timestep : Tensor):\n",
    "      ''' Apply noise to graph '''\n",
    "      noisy_nodes = torch.zeros(size = nodes.size(), device = nodes.device)\n",
    "      noisy_edges = torch.zeros(size = edges.size(), device = edges.device)\n",
    "\n",
    "      # nodes = batch_size x num_nodes x NODE_FEATURE_DIMENSION ; edges = batch_size x num_nodes x num_nodes x EDGE_FEATURE_DIMENSION\n",
    "      bernoulli_is_constructible = nodes[:,:,0] # batch_size x num_nodes x 1\n",
    "      categorical_primitive_types = nodes[:,:,1:6] # batch_size x num_nodes x 5\n",
    "      gaussian_primitive_parameters = nodes[:,:,6:] # batch_size x num_nodes x 14\n",
    "      # subnode just means if the constraint applies to the start, center, or end of a primitive\n",
    "      categorical_subnode_a_types = edges[:,:,:,0:4] # batch_size x num_nodes x 4\n",
    "      categorical_subnode_b_types = edges[:,:,:,4:8] # batch_size x num_nodes x 4\n",
    "      categorical_constraint_types = edges[:,:,:,8:] # batch_size x num_nodes x 9\n",
    "\n",
    "      # IsConstructible noise\n",
    "      noisy_nodes[:,:,0] = self.apply_binary_noise(bernoulli_is_constructible, timestep)\n",
    "      # Primitive Types noise\n",
    "      noisy_nodes[:,:,1:6] = self.apply_discrete_noise(categorical_primitive_types, timestep) # noised_primitive_types\n",
    "      # Primitive parameters noise\n",
    "      gaussian_noise = torch.randn_like(gaussian_primitive_parameters) # standard gaussian noise\n",
    "      noisy_nodes[:,:,6:] = self.apply_gaussian_noise(gaussian_primitive_parameters, timestep, gaussian_noise)\n",
    "      # Subnode A noise\n",
    "      noisy_edges[:,:,:,0:4] = self.apply_discrete_noise(categorical_subnode_a_types, timestep) # noised_subnode_a_types\n",
    "      # Subnode B noise\n",
    "      noisy_edges[:,:,:,4:8] = self.apply_discrete_noise(categorical_subnode_b_types, timestep) # noised_subnode_a_types\n",
    "      # Constraint Types noise\n",
    "      noisy_edges[:,:,:,8:] = self.apply_discrete_noise(categorical_constraint_types, timestep) # noised_constraint_types\n",
    "\n",
    "      return noisy_nodes, noisy_edges, gaussian_noise\n",
    "\n",
    "    def get_transition_noise(self, parameters : Tensor, timestep : int, gaussian_noise : Tensor = None):\n",
    "      if gaussian_noise is None:\n",
    "        gaussian_noise = torch.randn_like(parameters) # standard gaussian noise\n",
    "      return self.sqrt_precisions[timestep] * parameters + self.sqrt_variances[timestep] * gaussian_noise\n",
    "\n",
    "    def apply_gaussian_noise(self, parameters : Tensor, timestep : Tensor | int, gaussian_noise : Tensor = None):\n",
    "      if gaussian_noise is None:\n",
    "        gaussian_noise = torch.randn_like(parameters) # standard gaussian noise\n",
    "      \n",
    "      if type(timestep) is int: timestep = [timestep]\n",
    "      # parameters shape is batch_size x num_nodes x num_params\n",
    "      # gaussian_noise shape is batch_size x num_nodes x num_params\n",
    "      batched_precisions = self.sqrt_cumulative_precisions[timestep,None,None] # (b,1,1) or (1,1,1)\n",
    "      batched_variances = self.sqrt_cumulative_variances[timestep,None,None]   # (b,1,1) or (1,1,1)\n",
    "      return batched_precisions * parameters + batched_variances * gaussian_noise\n",
    "\n",
    "    def apply_gaussian_posterior_step(self, parameters : Tensor, pred_noise : Tensor, timestep : int):\n",
    "      var = self.variances[timestep]\n",
    "      sqrt_cumulative_var = self.sqrt_cumulative_variances[timestep]\n",
    "      sqrt_precision = self.sqrt_precisions[timestep]\n",
    "      \n",
    "      denoised_mean = (parameters - pred_noise * var / sqrt_cumulative_var) / sqrt_precision\n",
    "      if timestep > 1:\n",
    "        gaussian_noise = torch.randn_like(parameters)\n",
    "        return denoised_mean + gaussian_noise * self.sqrt_posterior_variances[timestep]\n",
    "      else:\n",
    "        return denoised_mean\n",
    "\n",
    "    def get_transition_matrix(self, dimension : int, timestep : int | Tensor):\n",
    "      if type(timestep) is int: assert timestep > 0; timestep = [timestep]\n",
    "      batched_precisions = self.sqrt_precisions[timestep,None,None] # (batch_size, 1, 1) or (1, 1, 1)\n",
    "      return batched_precisions * torch.eye(dimension, dtype = torch.float32, device = self.device) + (1 - batched_precisions) / dimension # (batch_size, d, d) or (1, d, d)\n",
    "\n",
    "    def get_cumulative_transition_matrix(self, dimension : int, timestep : int | Tensor):\n",
    "      if type(timestep) is int: assert timestep > 0; timestep = [timestep]\n",
    "      batched_precisions = self.sqrt_cumulative_precisions[timestep,None,None] # (batch_size, 1, 1) or (1, 1, 1)\n",
    "      return batched_precisions * torch.eye(dimension, dtype = torch.float32, device = self.device) + (1 - batched_precisions) / dimension # (batch_size, d, d) or (1, d, d)\n",
    "    \n",
    "    def get_posterior_transition_matrix(self, xt : Tensor, timestep : Tensor | int) -> torch.Tensor:\n",
    "      xt_size, xt = self.flatten_middle(xt) # (b, n, d) or (b, n * n, d), for convenience let m = n or n * n\n",
    "      d = xt_size[-1]\n",
    "\n",
    "      qt = xt @ self.get_transition_matrix(d, timestep).permute(0, 2, 1) # (b, m, d), since xt is onehot we are plucking out rows corresponding to p(x_t = class | x_(t-1))\n",
    "      qt_bar = xt @ self.get_cumulative_transition_matrix(d, timestep).permute(0, 2, 1) # (b, m, d), since xt is onehot we are plucking out rows corresponding to p(x_t = class | x_0)\n",
    "\n",
    "      q = qt.unsqueeze(2) / qt_bar.unsqueeze(3) # (b, m, d, d), perform an outer product so element at (b, m, i, j) = p(x_t = class | x_(t-1) = j) / p(x_t = class | x_0 = i)\n",
    "      q = q * self.get_cumulative_transition_matrix(d, timestep - 1).unsqueeze(1) # (b, m, d, d), broadcast multiply so element at (b, m, i, j) = p(x_t = class | x_(t-1) = j) * p(x_(t-1) = j | x_0 = i) / p(x_t = class | x_0 = i)\n",
    "\n",
    "      return q.view(size = xt_size + (d,)) # reshape into (b, n, d, d) or (b, n, n, d, d)\n",
    "\n",
    "    def apply_discrete_noise(self, x_one_hot : Tensor, timestep : Tensor | int):\n",
    "      size, x = self.flatten_middle(x_one_hot)\n",
    "      q = self.get_cumulative_transition_matrix(size[-1], timestep) # (b, d, d) or (1, d, d)\n",
    "      distribution = x @ q # (b, n, d) or (b, n * n, d)\n",
    "      distribution = distribution.view(size) # (b, n, d) or (b, n, n, d)\n",
    "      return self.sample_discrete_distribution(distribution).float()\n",
    "    \n",
    "    def apply_multinomial_posterior_step(self, classes_one_hot : Tensor, pred_class_probs : Tensor, timestep : int):\n",
    "      # classes_one_hot = (b, n, d) or (b, n, n, d)\n",
    "      # pred_class_probs = (b, n, d) or (b, n, n, d)\n",
    "      if timestep > 1:\n",
    "        q = self.get_posterior_transition_matrix(classes_one_hot, timestep) # (b, n, d, d) or (b, n, n, d, d)\n",
    "        pred_class_probs = pred_class_probs.unsqueeze(-2) # (b, n, 1, d) or (b, n, n, 1, d), make probs into row vector\n",
    "        posterior_distribution = pred_class_probs @ q # (b, n, 1, d) or (b, n, n, 1, d), batched vector-matrix multiply\n",
    "        posterior_distribution = posterior_distribution.squeeze(-2) # (b, n, d) or (b, n, n, d)\n",
    "        return self.sample_discrete_distribution(posterior_distribution).float()\n",
    "      else:\n",
    "        return pred_class_probs\n",
    "      \n",
    "    def apply_binary_noise(self, boolean_flag : Tensor, timestep : int | Tensor):\n",
    "      boolean_flag = boolean_flag.unsqueeze(-1)\n",
    "      one_hot = torch.cat([1 - boolean_flag, boolean_flag], dim = -1) # (b, n, 2)\n",
    "      noised_one_hot = self.apply_discrete_noise(one_hot, timestep) # (b, n, 2)\n",
    "      return noised_one_hot[...,1] # (b, n)\n",
    "\n",
    "    def apply_bernoulli_posterior_step(self, boolean_flag : Tensor, pred_boolean_prob : Tensor, timestep : int):\n",
    "      if timestep > 1:\n",
    "        boolean_flag = boolean_flag.unsqueeze(-1) # b, n, 1\n",
    "        pred_boolean_prob = pred_boolean_prob.unsqueeze(-1) # b, n, 1\n",
    "        one_hot_xt = torch.cat([1 - boolean_flag, boolean_flag], dim = -1) # (b, n, 2)\n",
    "        probs = torch.cat([1 - pred_boolean_prob, pred_boolean_prob], dim = -1) # (b, n, 2)\n",
    "        noised_one_hot = self.apply_multinomial_posterior_step(one_hot_xt, probs, timestep) # (b, n, 2)\n",
    "        return noised_one_hot[...,1] # (b, n)\n",
    "      else:\n",
    "        return pred_boolean_prob\n",
    "      \n",
    "    def sample_discrete_distribution(self, tensor : Tensor):\n",
    "       size = tensor.size()\n",
    "       num_classes = size[-1]\n",
    "       return F.one_hot(tensor.reshape(-1, num_classes).multinomial(1), num_classes).reshape(size)\n",
    "    \n",
    "    def flatten_middle(self, x : Tensor):\n",
    "      prev_size = x.size() # shape of x_one_hot is (b, n, d) or (b, n, n, d)\n",
    "      return prev_size, x.view(prev_size[0], -1, prev_size[-1]) # (b, n, d) or (b, n * n, d)\n",
    "\n",
    "# Graph Transformer Layer outlined by DiGress Graph Diffusion\n",
    "class TransformerLayer(nn.Module):\n",
    "    def __init__(self, num_heads : int, node_dim : int, edge_dim : int, device : torch.device):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.node_dim = node_dim\n",
    "        self.edge_dim = edge_dim\n",
    "\n",
    "        self.mlp_add_embs = nn.Sequential(nn.Linear(in_features = self.node_dim, out_features = self.node_dim, device = device),)\n",
    "        self.mlp_mul_embs = nn.Sequential(nn.Linear(in_features = self.node_dim, out_features = self.node_dim, device = device),)\n",
    "        \n",
    "        self.attention_heads = MultiHeadAttention(node_dim = self.node_dim, edge_dim = self.edge_dim, num_heads = self.num_heads, device = device)\n",
    "\n",
    "        self.layer_norm_nodes = nn.Sequential(nn.LayerNorm(normalized_shape = self.node_dim, device = device),\n",
    "                                              nn.LeakyReLU(.1)\n",
    "                                             )\n",
    "        self.layer_norm_edges = nn.Sequential(nn.LayerNorm(normalized_shape = self.edge_dim, device = device),\n",
    "                                              # nn.Dropout(p = 0.1)\n",
    "                                             )\n",
    "\n",
    "        self.mlp_nodes = nn.Sequential(nn.Linear(in_features = self.node_dim, out_features = self.node_dim, device = device),\n",
    "                                       nn.LeakyReLU(.1),\n",
    "                                    #    nn.Dropout(p = 0.1),\n",
    "                                       nn.Linear(in_features = self.node_dim, out_features = self.node_dim, device = device),\n",
    "                                      )\n",
    "        \n",
    "        self.mlp_edges = nn.Sequential(nn.Linear(in_features = self.edge_dim, out_features = self.edge_dim, device = device),\n",
    "                                       nn.LeakyReLU(.1),\n",
    "                                    #    nn.Dropout(p = 0.1),\n",
    "                                       nn.Linear(in_features = self.edge_dim, out_features = self.edge_dim, device = device),\n",
    "                                      )\n",
    "        \n",
    "        self.layer_norm_nodes2 = nn.Sequential(nn.LayerNorm(normalized_shape = self.node_dim, device = device),\n",
    "                                               nn.LeakyReLU(.1)\n",
    "                                              )\n",
    "        self.layer_norm_edges2 = nn.Sequential(nn.LayerNorm(normalized_shape = self.edge_dim, device = device),\n",
    "                                              #  nn.Dropout(p = 0.1)\n",
    "                                              )\n",
    "    \n",
    "    def forward(self, nodes : Tensor, edges : Tensor, time_embs : Tensor) -> Tuple[Tensor, Tensor, Tensor]:\n",
    "        # Incorporate timestep information\n",
    "        shifts = self.mlp_add_embs(time_embs)\n",
    "        scales = self.mlp_mul_embs(time_embs)\n",
    "\n",
    "        nodes = nodes + shifts.unsqueeze(1) + nodes * scales.unsqueeze(1) # batch_size x num_nodes x node_dim\n",
    "        edges = edges + shifts.unsqueeze(1).unsqueeze(1) + edges * scales.unsqueeze(1).unsqueeze(1) # batch_size x num_nodes x num_nodes x node_dim\n",
    "        # Perform multi head attention\n",
    "        attn_nodes, attn_edges = self.attention_heads(nodes, edges)\n",
    "\n",
    "        # Layer normalization with a skip connection\n",
    "        attn_nodes = self.layer_norm_nodes(attn_nodes + nodes) # batch_size x num_nodes x node_dim\n",
    "        attn_edges = self.layer_norm_edges(attn_edges + edges) # batch_size x num_nodes x num_nodes x edge_dim\n",
    "        del nodes\n",
    "        del edges\n",
    "\n",
    "        # MLP out\n",
    "        new_nodes = self.mlp_nodes(attn_nodes) # batch_size x num_nodes x node_dim\n",
    "        new_edges = self.mlp_edges(attn_edges) # batch_size x num_nodes x num_nodes x edge_dim\n",
    "\n",
    "        # Second layer normalization with a skip connection\n",
    "        new_nodes = self.layer_norm_nodes2(new_nodes + attn_nodes) # batch_size x num_nodes x node_dim\n",
    "        new_edges = self.layer_norm_edges2(new_edges + attn_edges) # batch_size x num_nodes x num_nodes x edge_dim\n",
    "        del attn_nodes\n",
    "        del attn_edges\n",
    "\n",
    "        new_embs = F.relu(shifts + scales + time_embs)\n",
    "        return new_nodes, new_edges, new_embs\n",
    "\n",
    "# Outer Product Attention Head\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, node_dim : int, edge_dim : int, num_heads : int, device : torch.device):\n",
    "        super().__init__()\n",
    "        self.node_dim = node_dim\n",
    "        self.edge_dim = edge_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attn_dim = node_dim // num_heads\n",
    "\n",
    "        self.lin_query = nn.Linear(in_features = self.node_dim, out_features = self.node_dim, device = device)\n",
    "        self.lin_key = nn.Linear(in_features = self.node_dim, out_features = self.node_dim, device = device)\n",
    "        self.lin_value = nn.Sequential(nn.Linear(in_features = self.node_dim, out_features = self.node_dim, device = device),\n",
    "                                      #  nn.LeakyReLU(.1),\n",
    "                                      #  nn.Linear(in_features = self.node_dim, out_features = self.node_dim, device = device)\n",
    "                                      )\n",
    "\n",
    "        self.lin_mul = nn.Sequential(nn.Linear(in_features = self.edge_dim, out_features = self.node_dim, device = device),\n",
    "                                    #  nn.GELU(approximate='tanh'),\n",
    "                                    #  nn.Linear(in_features = self.node_dim, out_features = self.node_dim, device = device)\n",
    "                                    )\n",
    "        self.lin_add = nn.Sequential(nn.Linear(in_features = self.edge_dim, out_features = self.node_dim, device = device),\n",
    "                                    #  nn.GELU(approximate='tanh'),\n",
    "                                    #  nn.Linear(in_features = self.node_dim, out_features = self.node_dim, device = device)\n",
    "                                    )\n",
    "        #self.edge_film = FiLM(self.edge_dim, self.node_dim, device = device)\n",
    "\n",
    "        self.lin_nodes_out = nn.Sequential(\n",
    "                                           nn.Linear(in_features = self.node_dim, out_features = self.node_dim, device = device),\n",
    "                                          #  nn.LeakyReLU(.1),\n",
    "                                          #  nn.Linear(in_features = self.node_dim, out_features = self.node_dim, device = device)\n",
    "                                          )\n",
    "        self.lin_edges_out = nn.Sequential(nn.LeakyReLU(.1),\n",
    "                                           nn.Linear(in_features = self.node_dim, out_features = self.node_dim, device = device),\n",
    "                                          #  nn.LeakyReLU(.1),\n",
    "                                          #  nn.Linear(in_features = self.node_dim, out_features = self.edge_dim, device = device)\n",
    "                                          )\n",
    "\n",
    "    def forward(self, nodes : Tensor, edges : Tensor):\n",
    "        batch_size, num_nodes, _ = nodes.size()\n",
    "        \n",
    "        # Outer Product Attention -------\n",
    "        queries = self.lin_query(nodes).view(batch_size, num_nodes, self.num_heads, -1) # batch_size x num_nodes x num_heads x attn_dim\n",
    "        keys = self.lin_key(nodes).view(batch_size, num_nodes, self.num_heads, -1)      # batch_size x num_nodes x num_heads x attn_dim\n",
    "        # queries = queries.unsqueeze(2)                            # batch_size x num_nodes x 1 x num_heads x attn_dim \n",
    "        # keys = keys.unsqueeze(1)                                  # batch_size x 1 x num_nodes x num_heads x attn_dim \n",
    "        attention = queries.unsqueeze(2) * keys.unsqueeze(1) / math.sqrt(self.node_dim) # batch_size x num_nodes x num_nodes x num_heads x attn_dim\n",
    "        del queries\n",
    "        del keys\n",
    "\n",
    "        # Condition attention based on edge features\n",
    "        edges_mul = self.lin_mul(edges).view(batch_size, num_nodes, num_nodes, self.num_heads, -1) # batch_size x num_nodes x num_nodes x num_heads x attn_dim\n",
    "        edges_add = self.lin_add(edges).view(batch_size, num_nodes, num_nodes, self.num_heads, -1) # batch_size x num_nodes x num_nodes x num_heads x attn_dim\n",
    "        del edges\n",
    "        new_edges = attention * edges_mul + attention + edges_add # batch_size x num_nodes x num_nodes x num_heads x attn_dim\n",
    "        del edges_add\n",
    "        del edges_mul\n",
    "        \n",
    "        # Normalize attention\n",
    "                                                                           # batch_size x num_nodes x num_nodes x num_heads (Finish dot product)\n",
    "        attention = torch.softmax(input = new_edges.sum(dim = 4), dim = 2) # batch_size x num_nodes x num_nodes x num_heads (softmax) \n",
    "\n",
    "        # Weight node representations and sum\n",
    "        values = self.lin_value(nodes).view(batch_size, num_nodes, self.num_heads, -1)  # batch_size x num_nodes x num_heads x attn_dim\n",
    "        del nodes\n",
    "                                                                                                             # batch_size x num_nodes x num_heads x attn_dim\n",
    "        weighted_values = (attention.unsqueeze(4) * values.unsqueeze(1)).sum(dim = 2).flatten(start_dim = 2) # batch_size x num_nodes x node_dim\n",
    "        del values\n",
    "        # Flatten attention heads\n",
    "        new_edges = new_edges.flatten(start_dim = 3)\n",
    "        # weighted_values = weighted_values.flatten(start_dim = 2)\n",
    "        \n",
    "        # Combine attention heads\n",
    "        new_nodes = self.lin_nodes_out(weighted_values)\n",
    "        new_edges = self.lin_edges_out(new_edges)\n",
    "\n",
    "        return new_nodes, new_edges\n",
    "    \n",
    "class SoftAttentionLayer(nn.Module):\n",
    "  def __init__(self, dim : int, num_heads : int, device : torch.device):\n",
    "    super().__init__()\n",
    "    self.device = device\n",
    "    self.node_dim = dim\n",
    "    self.edge_dim = dim\n",
    "    self.num_heads = num_heads\n",
    "    self.attn_dim = dim // num_heads\n",
    "    self.num_nodes = MAX_NUM_PRIMITIVES\n",
    "\n",
    "    concat_dim = 2 * self.node_dim + self.edge_dim\n",
    "    self.mlp_haggr_weights = nn.Sequential(nn.Linear(in_features = concat_dim, out_features = concat_dim, device = self.device),\n",
    "                                           nn.LeakyReLU(.1),\n",
    "                                           nn.Linear(in_features = concat_dim, out_features = 1, device = self.device),\n",
    "                                           nn.Softmax(dim = 2)\n",
    "                                          )\n",
    "    \n",
    "    self.mlp_haggr_values = nn.Sequential(nn.Linear(in_features = concat_dim, out_features = concat_dim, device = self.device),\n",
    "                                           nn.LeakyReLU(.1),\n",
    "                                           nn.Linear(in_features = concat_dim, out_features = self.node_dim, device = self.device),\n",
    "                                         )\n",
    "\n",
    "    self.query_key_value_mlp = nn.Linear(in_features = self.node_dim, out_features = 3 * self.node_dim, device = self.device)\n",
    "\n",
    "    self.layer_norm_embs = nn.Sequential(nn.LayerNorm(normalized_shape = self.node_dim, device = self.device),\n",
    "                                         nn.LeakyReLU(.1),\n",
    "                                        )\n",
    "\n",
    "    self.node_mlp = nn.Sequential(nn.Linear(in_features = self.node_dim, out_features = self.node_dim, device = self.device),\n",
    "                                  nn.LeakyReLU(.1),\n",
    "                                  nn.Linear(in_features = self.node_dim, out_features = self.node_dim, device = self.device),\n",
    "                                 )\n",
    "    self.edge_mlp = nn.Sequential(nn.Linear(in_features = 2 * self.node_dim, out_features = 2 * self.node_dim, device = self.device),\n",
    "                                  nn.LeakyReLU(.1),\n",
    "                                  nn.Linear(in_features = 2 * self.node_dim, out_features = self.node_dim, device = self.device),\n",
    "                                 )\n",
    "    \n",
    "    self.layer_norm_out_nodes = nn.Sequential(nn.LayerNorm(normalized_shape = self.node_dim, device = self.device),\n",
    "                                              nn.LeakyReLU(.1),\n",
    "                                             )\n",
    "    \n",
    "    self.layer_norm_out_edges = nn.Sequential(nn.LayerNorm(normalized_shape = self.node_dim, device = self.device),\n",
    "                                              nn.LeakyReLU(.1),\n",
    "                                             )\n",
    "    \n",
    "  def forward(self, nodes : Tensor, edges : Tensor) -> Tuple[Tensor, Tensor]:\n",
    "    # Outer Product Concatenation\n",
    "    hstack = nodes.unsqueeze(2).expand(-1, -1, self.num_nodes, -1) # (b, n, n, d)\n",
    "    vstack = hstack.permute(0, 2, 1, 3) # (b, n, n, d)\n",
    "    graph_features = torch.cat(tensors = (hstack, vstack, edges), dim = 3) # (b, n, n, 3 * d)\n",
    "\n",
    "    # Soft Attentional Encoder\n",
    "    haggr_weights = self.mlp_haggr_weights(graph_features).permute(0, 1, 3, 2) # (b, n, 1, n)\n",
    "    haggr_values = self.mlp_haggr_values(graph_features) # (b, n, n, d)\n",
    "    graph_embs = (haggr_weights @ haggr_values).squeeze(2) # (b, n, d)\n",
    "\n",
    "    # Low Dimensional Attention\n",
    "    b, n, d = graph_embs.size()\n",
    "    query_key_value = self.query_key_value_mlp(graph_embs).view(b, n, self.num_heads, 3 * self.attn_dim).permute(0, 2, 1, 3) # (b, h, n, 3 * attn_dim)\n",
    "    queries, keys, values = query_key_value.reshape(b * self.num_heads, n, 3 * self.attn_dim).chunk(3, dim = 2) # (b * h, n, attn_dim) is shape for the three tensors\n",
    "    attn_embs = F.scaled_dot_product_attention(queries, keys, values).view(b, self.num_heads, n, self.attn_dim) # (b * h, n, attn_dim)\n",
    "    attn_embs = attn_embs.permute(0, 2, 1, 3).reshape(b, n, self.node_dim) # (b, n, d)\n",
    "\n",
    "    # Residual Connection and LayerNorm\n",
    "    self.layer_norm_embs(attn_embs + graph_embs)\n",
    "\n",
    "    # Outer Product Decoder\n",
    "    emb_hstack = attn_embs.unsqueeze(2).expand(-1, -1, self.num_nodes, -1) # (b, n, n, d)\n",
    "    emb_vstack = emb_hstack.permute(0, 2, 1, 3) # (b, n, n, d)\n",
    "    emb_edges = torch.cat(tensors = (emb_hstack, emb_vstack), dim = 3) # (b, n, n, 2 * d)\n",
    "\n",
    "    new_edges = self.edge_mlp(emb_edges) # (b, n, n, d)\n",
    "    new_nodes = self.node_mlp(attn_embs) # (b, n, d)\n",
    "\n",
    "    # Residual Connection and LayerNorm\n",
    "    new_edges = self.layer_norm_out_nodes(new_edges + new_edges)\n",
    "    new_nodes = self.layer_norm_out_nodes(new_nodes + nodes)\n",
    "\n",
    "    return new_nodes, new_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = CosineNoiseScheduler(max_timestep = 500, device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T = 500\n",
    "# offset = .008\n",
    "# precisions = torch.cos((torch.linspace(0, 1, T + 1) + offset) * 0.5 * math.pi / (1 + offset)) ** 2\n",
    "plt.plot(torch.linspace(0, scheduler.max_timestep, scheduler.max_steps), scheduler.sqrt_posterior_variances)\n",
    "scheduler.sqrt_posterior_variances[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GD3PM(device = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-7.1943e-02,  3.8405e-02, -3.8214e-03,  ...,  8.6844e-01,\n",
       "           -8.0635e-03,  5.0961e-01],\n",
       "          [ 4.4182e-01,  3.8175e-01,  7.4728e-01,  ..., -4.6879e-02,\n",
       "           -6.0337e-02, -4.6395e-02],\n",
       "          [ 1.8042e+00, -3.1544e-02, -2.0649e-01,  ...,  1.4710e+00,\n",
       "            1.3961e+00,  5.4910e-01],\n",
       "          ...,\n",
       "          [ 1.0218e+00,  1.1989e+00,  1.1728e+00,  ..., -9.2041e-03,\n",
       "           -1.0685e-02, -2.6172e-02],\n",
       "          [-9.1021e-02,  1.6088e-03,  1.0256e+00,  ..., -9.2267e-02,\n",
       "            1.0816e+00, -1.2574e-01],\n",
       "          [ 1.8320e+00, -1.7733e-02, -3.9278e-02,  ...,  6.8177e-01,\n",
       "           -2.4127e-02,  9.4185e-01]],\n",
       " \n",
       "         [[ 2.2566e+00,  1.1865e+00, -3.6246e-02,  ..., -2.0274e-01,\n",
       "           -1.3671e-01, -6.7719e-02],\n",
       "          [-8.2890e-02, -1.2020e-01,  6.7462e-01,  ...,  1.1532e-01,\n",
       "           -5.6733e-02,  8.8157e-01],\n",
       "          [-6.2868e-02, -1.9113e-02,  9.2896e-01,  ..., -3.1593e-03,\n",
       "            5.5211e-01, -9.2183e-02],\n",
       "          ...,\n",
       "          [-1.1557e-01,  1.7976e+00,  2.1001e-01,  ..., -1.0767e-01,\n",
       "           -1.0357e-01,  1.4127e+00],\n",
       "          [-1.0609e-02,  1.0302e+00, -1.5162e-01,  ..., -1.0710e-02,\n",
       "           -6.6192e-02,  9.3589e-01],\n",
       "          [ 1.5480e+00,  1.5470e-01, -7.5524e-02,  ..., -7.8797e-02,\n",
       "            8.8484e-01, -8.2292e-02]]], device='cuda:2',\n",
       "        grad_fn=<LeakyReluBackward0>),\n",
       " tensor([[[[-0.1490,  0.9779,  0.5898,  ...,  0.7861,  0.2841,  0.9320],\n",
       "           [-0.1491,  0.9779,  0.5899,  ...,  0.7863,  0.2844,  0.9315],\n",
       "           [-0.1490,  0.9780,  0.5893,  ...,  0.7862,  0.2842,  0.9317],\n",
       "           ...,\n",
       "           [-0.1491,  0.9781,  0.5897,  ...,  0.7861,  0.2842,  0.9318],\n",
       "           [-0.1490,  0.9780,  0.5896,  ...,  0.7863,  0.2843,  0.9316],\n",
       "           [-0.1491,  0.9781,  0.5895,  ...,  0.7860,  0.2843,  0.9317]],\n",
       " \n",
       "          [[-0.1490,  0.9784,  0.5895,  ...,  0.7862,  0.2839,  0.9319],\n",
       "           [-0.1491,  0.9784,  0.5897,  ...,  0.7865,  0.2842,  0.9314],\n",
       "           [-0.1490,  0.9785,  0.5891,  ...,  0.7863,  0.2840,  0.9316],\n",
       "           ...,\n",
       "           [-0.1491,  0.9786,  0.5895,  ...,  0.7862,  0.2840,  0.9317],\n",
       "           [-0.1490,  0.9785,  0.5894,  ...,  0.7865,  0.2842,  0.9315],\n",
       "           [-0.1491,  0.9786,  0.5893,  ...,  0.7861,  0.2841,  0.9316]],\n",
       " \n",
       "          [[-0.1490,  0.9782,  0.5898,  ...,  0.7862,  0.2840,  0.9320],\n",
       "           [-0.1490,  0.9782,  0.5900,  ...,  0.7865,  0.2842,  0.9315],\n",
       "           [-0.1489,  0.9783,  0.5894,  ...,  0.7863,  0.2841,  0.9317],\n",
       "           ...,\n",
       "           [-0.1490,  0.9784,  0.5898,  ...,  0.7862,  0.2841,  0.9318],\n",
       "           [-0.1490,  0.9783,  0.5897,  ...,  0.7865,  0.2842,  0.9316],\n",
       "           [-0.1490,  0.9784,  0.5896,  ...,  0.7861,  0.2841,  0.9317]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.1491,  0.9779,  0.5900,  ...,  0.7862,  0.2840,  0.9317],\n",
       "           [-0.1491,  0.9779,  0.5902,  ...,  0.7865,  0.2843,  0.9312],\n",
       "           [-0.1490,  0.9780,  0.5896,  ...,  0.7863,  0.2841,  0.9313],\n",
       "           ...,\n",
       "           [-0.1491,  0.9781,  0.5900,  ...,  0.7862,  0.2842,  0.9315],\n",
       "           [-0.1491,  0.9780,  0.5899,  ...,  0.7865,  0.2843,  0.9313],\n",
       "           [-0.1491,  0.9781,  0.5898,  ...,  0.7861,  0.2842,  0.9313]],\n",
       " \n",
       "          [[-0.1490,  0.9781,  0.5901,  ...,  0.7863,  0.2841,  0.9318],\n",
       "           [-0.1491,  0.9781,  0.5902,  ...,  0.7865,  0.2844,  0.9313],\n",
       "           [-0.1490,  0.9782,  0.5896,  ...,  0.7864,  0.2842,  0.9315],\n",
       "           ...,\n",
       "           [-0.1491,  0.9783,  0.5900,  ...,  0.7863,  0.2842,  0.9317],\n",
       "           [-0.1490,  0.9782,  0.5899,  ...,  0.7865,  0.2843,  0.9314],\n",
       "           [-0.1491,  0.9783,  0.5898,  ...,  0.7861,  0.2843,  0.9315]],\n",
       " \n",
       "          [[-0.1490,  0.9780,  0.5897,  ...,  0.7858,  0.2840,  0.9322],\n",
       "           [-0.1490,  0.9781,  0.5898,  ...,  0.7860,  0.2843,  0.9317],\n",
       "           [-0.1490,  0.9781,  0.5893,  ...,  0.7859,  0.2841,  0.9319],\n",
       "           ...,\n",
       "           [-0.1490,  0.9782,  0.5896,  ...,  0.7858,  0.2841,  0.9320],\n",
       "           [-0.1490,  0.9782,  0.5896,  ...,  0.7860,  0.2842,  0.9318],\n",
       "           [-0.1490,  0.9783,  0.5895,  ...,  0.7856,  0.2841,  0.9319]]],\n",
       " \n",
       " \n",
       "         [[[-0.1541,  0.9106,  0.6220,  ...,  0.8369,  0.2554,  0.9012],\n",
       "           [-0.1541,  0.9106,  0.6219,  ...,  0.8368,  0.2554,  0.9014],\n",
       "           [-0.1541,  0.9106,  0.6218,  ...,  0.8368,  0.2552,  0.9016],\n",
       "           ...,\n",
       "           [-0.1541,  0.9108,  0.6221,  ...,  0.8369,  0.2552,  0.9013],\n",
       "           [-0.1541,  0.9107,  0.6219,  ...,  0.8368,  0.2552,  0.9015],\n",
       "           [-0.1541,  0.9105,  0.6218,  ...,  0.8367,  0.2555,  0.9014]],\n",
       " \n",
       "          [[-0.1541,  0.9105,  0.6220,  ...,  0.8368,  0.2554,  0.9014],\n",
       "           [-0.1541,  0.9105,  0.6219,  ...,  0.8366,  0.2554,  0.9016],\n",
       "           [-0.1541,  0.9105,  0.6217,  ...,  0.8366,  0.2552,  0.9018],\n",
       "           ...,\n",
       "           [-0.1541,  0.9107,  0.6221,  ...,  0.8367,  0.2552,  0.9015],\n",
       "           [-0.1541,  0.9106,  0.6218,  ...,  0.8366,  0.2552,  0.9017],\n",
       "           [-0.1541,  0.9104,  0.6218,  ...,  0.8366,  0.2555,  0.9016]],\n",
       " \n",
       "          [[-0.1541,  0.9106,  0.6219,  ...,  0.8367,  0.2555,  0.9015],\n",
       "           [-0.1541,  0.9106,  0.6218,  ...,  0.8365,  0.2555,  0.9017],\n",
       "           [-0.1541,  0.9106,  0.6217,  ...,  0.8365,  0.2553,  0.9019],\n",
       "           ...,\n",
       "           [-0.1541,  0.9107,  0.6220,  ...,  0.8366,  0.2553,  0.9016],\n",
       "           [-0.1541,  0.9106,  0.6217,  ...,  0.8365,  0.2553,  0.9018],\n",
       "           [-0.1541,  0.9104,  0.6217,  ...,  0.8365,  0.2556,  0.9017]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.1541,  0.9104,  0.6219,  ...,  0.8368,  0.2554,  0.9013],\n",
       "           [-0.1541,  0.9104,  0.6218,  ...,  0.8366,  0.2553,  0.9015],\n",
       "           [-0.1541,  0.9104,  0.6216,  ...,  0.8366,  0.2552,  0.9017],\n",
       "           ...,\n",
       "           [-0.1542,  0.9106,  0.6220,  ...,  0.8367,  0.2552,  0.9014],\n",
       "           [-0.1541,  0.9105,  0.6217,  ...,  0.8366,  0.2551,  0.9017],\n",
       "           [-0.1541,  0.9103,  0.6217,  ...,  0.8366,  0.2555,  0.9015]],\n",
       " \n",
       "          [[-0.1541,  0.9104,  0.6221,  ...,  0.8366,  0.2556,  0.9014],\n",
       "           [-0.1541,  0.9104,  0.6220,  ...,  0.8365,  0.2556,  0.9016],\n",
       "           [-0.1541,  0.9104,  0.6218,  ...,  0.8365,  0.2555,  0.9018],\n",
       "           ...,\n",
       "           [-0.1541,  0.9106,  0.6222,  ...,  0.8366,  0.2555,  0.9015],\n",
       "           [-0.1541,  0.9105,  0.6219,  ...,  0.8365,  0.2554,  0.9017],\n",
       "           [-0.1541,  0.9103,  0.6219,  ...,  0.8364,  0.2557,  0.9016]],\n",
       " \n",
       "          [[-0.1541,  0.9107,  0.6223,  ...,  0.8368,  0.2556,  0.9010],\n",
       "           [-0.1541,  0.9107,  0.6222,  ...,  0.8367,  0.2555,  0.9013],\n",
       "           [-0.1541,  0.9107,  0.6221,  ...,  0.8367,  0.2554,  0.9014],\n",
       "           ...,\n",
       "           [-0.1541,  0.9108,  0.6224,  ...,  0.8368,  0.2554,  0.9011],\n",
       "           [-0.1541,  0.9108,  0.6221,  ...,  0.8367,  0.2553,  0.9014],\n",
       "           [-0.1541,  0.9106,  0.6221,  ...,  0.8366,  0.2557,  0.9013]]]],\n",
       "        device='cuda:2', grad_fn=<LeakyReluBackward0>))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = torch.randn(2, 24, 32).to(2)\n",
    "edges = torch.randn(2, 24, 24, 32).to(2)\n",
    "\n",
    "layer = SoftAttentionLayer(32, 8, 2)\n",
    "\n",
    "layer(nodes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_nodes = torch.cat((dataset.nodes[0].unsqueeze(0), dataset.nodes[1].unsqueeze(0)), dim = 0)\n",
    "true_edges = torch.cat((dataset.edges[0].unsqueeze(0), dataset.edges[1].unsqueeze(0)), dim = 0)\n",
    "timesteps = torch.randint(0, scheduler.max_steps, (2,))\n",
    "nodes, edges, _ = scheduler(true_nodes, true_edges, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SketchDataset('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = dataset.nodes[0]\n",
    "edges = dataset.edges[0]\n",
    "noisy_nodes, noisy_edges, _ = scheduler(nodes.unsqueeze(0), edges.unsqueeze(0), 0)\n",
    "sketch = SketchDataset.preds_to_sketch(nodes, edges)\n",
    "noised_sketch = SketchDataset.preds_to_sketch(noisy_nodes.squeeze(0), noisy_edges.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def fig_to_tensor(fig):\n",
    "    with io.BytesIO() as buff:\n",
    "        fig.savefig(buff, format='raw')\n",
    "        buff.seek(0)\n",
    "        data = torch.frombuffer(buff.getvalue(), dtype=torch.uint8)\n",
    "    w, h = fig.canvas.get_width_height()\n",
    "    plt.close()\n",
    "    return data.reshape((int(h), int(w), -1)).permute(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(f'runs2/new_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(f\"model_checkpoint_gd3pm_ddp_Adam_mse-25_kld-.001_24layers16heads256hidden.pth\")\n",
    "\n",
    "from collections import OrderedDict\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] # remove 'module.' of dataparallel\n",
    "    new_state_dict[name]=v\n",
    "\n",
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = CosineNoiseScheduler(max_timestep = 500, device = 2)\n",
    "\n",
    "vid_tensor = torch.zeros(size = (2, scheduler.max_steps, 4, 480, 640))\n",
    "nodes = torch.cat([dataset.nodes[0].unsqueeze(0), dataset.nodes[1].unsqueeze(0)], dim = 0) # 2 x num_nodes x node_features\n",
    "edges = torch.cat([dataset.edges[0].unsqueeze(0), dataset.edges[1].unsqueeze(0)], dim = 0) # 2 x num_nodes x num_nodes x edge_features\n",
    "nodes = nodes.to(2)\n",
    "edges = edges.to(2)\n",
    "\n",
    "for timestep in range(1, scheduler.max_steps):\n",
    "    nodes, edges, _ = scheduler(nodes, edges, timestep)\n",
    "    \n",
    "    vid_tensor[0][timestep] = fig_to_tensor(datalib.render_sketch(SketchDataset.preds_to_sketch(nodes[0].squeeze(0), edges[0].squeeze(0))))\n",
    "    vid_tensor[1][timestep] = fig_to_tensor(datalib.render_sketch(SketchDataset.preds_to_sketch(nodes[1].squeeze(0), edges[1].squeeze(0))))\n",
    "\n",
    "\n",
    "writer.add_video(\"Forward Process 2\", vid_tensor, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_test(noise_scheduler, nodes, edges, true_nodes, true_edges, timestep):\n",
    "    # IsConstructible denoising\n",
    "      nodes[:,:,0] = noise_scheduler.apply_bernoulli_posterior_step(nodes[:,:,0], true_nodes[:,:,0], timestep)\n",
    "      # Primitive Types denoising\n",
    "      nodes[:,:,1:6] = noise_scheduler.apply_multinomial_posterior_step(nodes[:,:,1:6], true_nodes[:,:,1:6], timestep)\n",
    "      # Primitive parameters denoising\n",
    "      true_noise = (nodes[:,:,6:] - noise_scheduler.sqrt_cumulative_precisions[timestep] * true_nodes[:,:,6:]) / noise_scheduler.sqrt_cumulative_variances[timestep]\n",
    "      nodes[:,:,6:] = noise_scheduler.apply_gaussian_posterior_step(nodes[:,:,6:], true_noise, timestep)\n",
    "      # Subnode A denoising\n",
    "      edges[:,:,:,0:4] = noise_scheduler.apply_multinomial_posterior_step(edges[:,:,:,0:4], true_edges[:,:,:,0:4], timestep)\n",
    "      # Subnode B denoising\n",
    "      edges[:,:,:,4:8] = noise_scheduler.apply_multinomial_posterior_step(edges[:,:,:,4:8], true_edges[:,:,:,4:8], timestep)\n",
    "      # Constraint Types denoising\n",
    "      edges[:,:,:,8:] = noise_scheduler.apply_multinomial_posterior_step(edges[:,:,:,8:], true_edges[:,:,:,8:], timestep)\n",
    "      return nodes, edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_tensor = torch.zeros(size = (2, model.noise_scheduler.max_steps, 4, 480, 640))\n",
    "nodes = torch.cat([dataset.nodes[0].unsqueeze(0), dataset.nodes[1].unsqueeze(0)], dim = 0) # 2 x num_nodes x node_features\n",
    "edges = torch.cat([dataset.edges[0].unsqueeze(0), dataset.edges[1].unsqueeze(0)], dim = 0) # 2 x num_nodes x num_nodes x edge_features\n",
    "true_nodes = nodes.to(2)\n",
    "true_edges = edges.to(2)\n",
    "\n",
    "nodes, edges = model.noise(true_nodes, true_edges)\n",
    "last_step = model.noise_scheduler.max_steps - 1\n",
    "for timestep in reversed(range(1, model.noise_scheduler.max_steps)):\n",
    "    true_noise = (nodes[:,:,6:] - model.noise_scheduler.sqrt_cumulative_precisions[timestep] * true_nodes[:,:,6:]) / model.noise_scheduler.sqrt_cumulative_variances[timestep]\n",
    "    temp_nodes = true_nodes.clone().to(2)\n",
    "    temp_nodes[:,:,6:] = true_noise\n",
    "    \n",
    "    nodes, edges = model.reverse_step(nodes, edges, temp_nodes, true_edges, timestep)\n",
    "    # Fill tensor in reverse order\n",
    "    vid_tensor[0][last_step - timestep] = fig_to_tensor(datalib.render_sketch(SketchDataset.preds_to_sketch(nodes[0].squeeze(0), edges[0].squeeze(0))))\n",
    "    vid_tensor[1][last_step - timestep] = fig_to_tensor(datalib.render_sketch(SketchDataset.preds_to_sketch(nodes[1].squeeze(0), edges[1].squeeze(0))))\n",
    "\n",
    "writer.add_video(\"Reverse Process 2\", vid_tensor, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_video(\"Forward Process\", vid_tensor, 0, 1)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[255., 255., 255.,  ..., 255., 255., 255.],\n",
       "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
       "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
       "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
       "         [255., 255., 255.,  ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.,  ..., 255., 255., 255.],\n",
       "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
       "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
       "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
       "         [255., 255., 255.,  ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.,  ..., 255., 255., 255.],\n",
       "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
       "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
       "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
       "         [255., 255., 255.,  ..., 255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.,  ..., 255., 255., 255.],\n",
       "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
       "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
       "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
       "         [255., 255., 255.,  ..., 255., 255., 255.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid_tensor[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = torch.randn(size = (3, 24, 2))\n",
    "x = torch.randn(size = (2, 2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.2011e+00, -4.6220e-01],\n",
      "         [-1.7614e+00,  8.0611e-01],\n",
      "         [ 2.7006e-01, -1.8678e+00],\n",
      "         [-8.5972e-01, -4.4823e-01],\n",
      "         [ 9.2746e-01, -7.0386e-01],\n",
      "         [-1.0524e+00,  1.6565e+00],\n",
      "         [ 1.5218e-01,  1.2881e+00],\n",
      "         [-7.5594e-02,  3.0399e-02],\n",
      "         [-7.5931e-01,  2.2981e+00],\n",
      "         [ 6.4255e-01,  1.4393e-01],\n",
      "         [ 1.0635e-01,  2.8390e-01],\n",
      "         [-4.8726e-04, -1.1606e+00],\n",
      "         [-1.2173e+00, -8.3023e-01],\n",
      "         [-5.5989e-01, -7.9893e-02],\n",
      "         [-5.3027e-01,  1.5316e-01],\n",
      "         [-1.4280e-01,  7.5005e-01],\n",
      "         [ 1.2629e-02,  8.7853e-01],\n",
      "         [ 6.3101e-01,  1.6780e-01],\n",
      "         [-1.0147e+00,  4.6798e-01],\n",
      "         [ 9.1126e-01, -4.4612e-01],\n",
      "         [ 2.6410e-01, -3.6911e-02],\n",
      "         [ 7.8104e-02,  7.2003e-01],\n",
      "         [ 5.6776e-01,  8.4092e-01],\n",
      "         [ 3.8145e-01,  1.3298e+00]],\n",
      "\n",
      "        [[ 6.7772e-01, -7.9119e-01],\n",
      "         [ 9.4839e-01, -1.5864e-02],\n",
      "         [ 1.8776e+00, -2.9493e+00],\n",
      "         [ 2.0662e+00, -9.6172e-01],\n",
      "         [-2.5308e-01,  4.0032e-01],\n",
      "         [-9.2715e-01,  6.6915e-01],\n",
      "         [-7.2289e-01,  9.9193e-01],\n",
      "         [-1.6077e+00,  1.6543e+00],\n",
      "         [-1.2766e+00,  1.4261e+00],\n",
      "         [-1.2972e+00,  1.5588e-01],\n",
      "         [ 5.1976e-01, -1.3330e-02],\n",
      "         [ 6.5292e-02,  9.8959e-01],\n",
      "         [ 3.8892e-01,  5.3079e-01],\n",
      "         [ 7.5154e-01,  2.4174e+00],\n",
      "         [-4.4034e-02,  1.2855e+00],\n",
      "         [-1.6213e-01, -1.2807e+00],\n",
      "         [-5.7606e-01, -5.1962e-01],\n",
      "         [-1.4495e+00,  2.1417e-01],\n",
      "         [ 1.4747e-01, -9.1861e-01],\n",
      "         [-1.3197e-01, -1.4801e+00],\n",
      "         [-3.1449e-01,  1.0875e+00],\n",
      "         [-6.3373e-01,  3.1997e-01],\n",
      "         [ 1.1099e+00,  8.0309e-01],\n",
      "         [-4.7622e-01, -2.6707e-01]],\n",
      "\n",
      "        [[-5.2966e-01, -1.7676e-03],\n",
      "         [-6.2505e-01, -7.6294e-01],\n",
      "         [-7.2052e-01, -2.0245e-01],\n",
      "         [-1.4847e+00, -2.9698e-01],\n",
      "         [-1.4952e+00,  4.0529e-03],\n",
      "         [ 4.4619e-01, -7.6595e-01],\n",
      "         [-1.9754e+00, -1.5146e+00],\n",
      "         [ 1.5299e+00, -5.5093e-01],\n",
      "         [ 1.0678e+00, -1.0056e+00],\n",
      "         [-2.3935e-01,  1.4527e+00],\n",
      "         [-5.7133e-01, -2.2968e+00],\n",
      "         [ 2.1838e+00,  2.4338e+00],\n",
      "         [ 1.4677e+00, -8.0575e-01],\n",
      "         [ 9.1130e-01, -2.7506e-02],\n",
      "         [-1.9516e+00, -1.5324e+00],\n",
      "         [-1.0827e+00, -9.6668e-01],\n",
      "         [-4.0764e-01,  1.1392e+00],\n",
      "         [-5.7447e-01,  1.1311e+00],\n",
      "         [-7.8011e-02,  1.3982e+00],\n",
      "         [ 6.0193e-01, -4.3604e-01],\n",
      "         [-5.3011e-01,  1.0782e+00],\n",
      "         [ 1.1119e+00, -9.6213e-01],\n",
      "         [ 5.9709e-02,  1.3348e+00],\n",
      "         [-1.6605e+00,  2.4779e-01]]])\n",
      "tensor([[[ 0.7419, -0.6273],\n",
      "         [-0.6088, -1.1886]],\n",
      "\n",
      "        [[-0.3159, -0.8883],\n",
      "         [-0.7126,  1.8743]]])\n"
     ]
    }
   ],
   "source": [
    "print(timestep)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 24, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "post = torch.einsum('bij,jkt->bikt', timestep, x)\n",
    "print(post.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 24, 1, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 24, 1, 2])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_flag = F.one_hot(torch.ones(3, 24, 2).reshape(3 * 24, 2).multinomial(1), 2).reshape(3, 24, 2).unsqueeze(2)\n",
    "print(bool_flag.size())\n",
    "out = bool_flag.float() @ post\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.0195,  0.8963],\n",
      "          [ 0.4355,  0.3487]],\n",
      "\n",
      "         [[-1.1306, -1.1809],\n",
      "          [-1.3799, -1.1867]],\n",
      "\n",
      "         [[ 0.4282, -0.9926],\n",
      "          [-0.5353, -1.1723]],\n",
      "\n",
      "         [[ 0.4859, -0.3495],\n",
      "          [ 0.6585, -1.6807]],\n",
      "\n",
      "         [[-0.2893,  1.2866],\n",
      "          [-0.8726, -0.1874]]]])\n",
      "tensor([[[1],\n",
      "         [0],\n",
      "         [0],\n",
      "         [1],\n",
      "         [1]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4355,  0.3487],\n",
       "         [-1.1306, -1.1809],\n",
       "         [ 0.4282, -0.9926],\n",
       "         [ 0.6585, -1.6807],\n",
       "         [-0.8726, -0.1874]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = torch.randn(1, 5, 2, 2)\n",
    "bool_flag = torch.ones(1, 5, 2).reshape(1 * 5, 2).multinomial(1).reshape(1, 5, 1)\n",
    "print(temp)\n",
    "print(bool_flag)\n",
    "\n",
    "temp.gather(2, bool_flag.expand(-1, -1, 2).unsqueeze(2)).squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9, 3],\n",
      "        [9, 9]])\n",
      "tensor([[4, 3],\n",
      "        [7, 6]])\n",
      "tensor([[5, 8],\n",
      "        [8, 6]])\n"
     ]
    }
   ],
   "source": [
    "qt = torch.randint(1, 10, (2, 2))\n",
    "qt_1bar = torch.randint(1, 10, (2, 2))\n",
    "qt_bar = torch.randint(1, 10, (2, 2))\n",
    "print(qt)\n",
    "print(qt_1bar)\n",
    "print(qt_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[7.2000, 5.4000],\n",
       "         [7.8750, 6.7500]],\n",
       "\n",
       "        [[1.5000, 3.3750],\n",
       "         [3.5000, 9.0000]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_posterior_xt_x0 = (qt.T.unsqueeze(1) * qt_1bar.unsqueeze(0)) / qt_bar.T.unsqueeze(2)\n",
    "cond_posterior_xt_x0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
