{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52c3ee32",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc027bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from dataset import SketchDataset\n",
    "from diffusion_model import GD3PM, CosineNoiseScheduler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Create a new OrderedDict without the 'module.' prefix\n",
    "def DDP_to_normal(state_dict):\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        # Remove 'module.' in the name\n",
    "        name = k[7:]\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    return new_state_dict\n",
    "\n",
    "# Freeze model parameters\n",
    "def freeze_model(model):\n",
    "    model.eval()\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "# Evaluation Vars\n",
    "GPU = 0\n",
    "OUTPUT_DIR = \"evaluation_outputs/\"\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cbc1cf",
   "metadata": {},
   "source": [
    "Load and freeze DDP (Distributed Data Parallel) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b9762",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_model = GD3PM(GPU)\n",
    "diff_state_dict = torch.load(\"checkpoint_nodediff_ddp_adam_nopos_32layers_512nodedim_512condim_8heads_2000denoisingsteps.pth\", map_location = {'cuda:%d' % 0: 'cuda:%d' % GPU})[\"model\"]\n",
    "diff_model.load_state_dict(DDP_to_normal(diff_state_dict))\n",
    "freeze_model(diff_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d81ea6",
   "metadata": {},
   "source": [
    "Sample and Visualize CAD Sketches from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068f7020",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 4\n",
    "with torch.no_grad():\n",
    "    seed = diff_model.noise_scheduler.sample_latent(num_samples)\n",
    "    nodes = diff_model.denoise(seed)\n",
    "    for i in range(nodes.size(0)):\n",
    "        SketchDataset.render_graph(nodes[i].cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cc4005",
   "metadata": {},
   "source": [
    "Load and extract the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecf3465",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---Loading Dataset---\")\n",
    "dataset = SketchDataset(\"data\")\n",
    "train_set, validate_set, test_set = random_split(dataset = dataset, lengths = [0.9, 0.05, 0.05], generator = torch.Generator().manual_seed(config.DATASET_SPLIT_SEED))\n",
    "print(\"---Finished Loading Dataset---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc617af",
   "metadata": {},
   "source": [
    "# Evaluate Log-Likelihood/ELBO (Evidence Lower Bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4e030d",
   "metadata": {},
   "source": [
    "$$ELBO=\\frac{T}{2}\\mathbb{E}_{t \\sim U(0,1),\\epsilon \\sim N(0,1)} [(SNR(\\frac{t-1}{T}) - SNR(\\frac{t}{T}))|x_0-\\hat{x}_0(x_t,t)|^2]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b96d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates delta SNR\n",
    "def nll_scale(a_bar, prev_a_bar):\n",
    "    return prev_a_bar / (1 - prev_a_bar) - a_bar / (1 - a_bar)\n",
    "\n",
    "# Calculate the ELBO of a batch of sketches\n",
    "def diffusion_elbo(true_nodes : Tensor, pred_nodes : Tensor, params_mask : Tensor, t, scheduler : CosineNoiseScheduler): \n",
    "    constructible_var = nll_scale(scheduler.continous_variance_to_discrete_variance(scheduler.a_bar[t], D = 2), scheduler.continous_variance_to_discrete_variance(scheduler.a_bar[t - 1], D = 2))\n",
    "    constructible_var = constructible_var.unsqueeze(-1).unsqueeze(1)\n",
    "    node_elbo = torch.sum(constructible_var * (pred_nodes[...,config.NODE_BOOL_SLICE] - true_nodes[...,config.NODE_BOOL_SLICE]) ** 2)\n",
    "\n",
    "    primitive_var = nll_scale(scheduler.continous_variance_to_discrete_variance(scheduler.a_bar[t], D = 5), scheduler.continous_variance_to_discrete_variance(scheduler.a_bar[t - 1], D = 5))\n",
    "    primitive_var = primitive_var.unsqueeze(-1).unsqueeze(1)\n",
    "    node_elbo += torch.sum(primitive_var * (pred_nodes[...,config.NODE_TYPE_SLICE] - true_nodes[...,config.NODE_TYPE_SLICE]) ** 2)\n",
    "\n",
    "    parameter_var = nll_scale(scheduler.a_bar[t], scheduler.a_bar[t - 1])\n",
    "    parameter_var = parameter_var.unsqueeze(-1).unsqueeze(1)\n",
    "    node_elbo += torch.sum(parameter_var * params_mask * (pred_nodes[...,config.NODE_PARM_SLICE] - true_nodes[...,config.NODE_PARM_SLICE]) ** 2)\n",
    "\n",
    "    return node_elbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35c75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset = test_set, batch_size = BATCH_SIZE)\n",
    "sum = 0\n",
    "\n",
    "# ELBO/VLB calculation using monte carlo estimation see Kingma et al. \"Variational Diffusion models\"\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(test_loader)\n",
    "    for nodes, params_mask in pbar:\n",
    "        nodes = nodes.to(GPU)\n",
    "        params_mask = params_mask.to(GPU)\n",
    "\n",
    "        t = torch.randint(low = 1, high = diff_model.max_timestep, size = (nodes.size(0),)).to(GPU)\n",
    "        noised_nodes = diff_model.noise_scheduler(nodes, t)\n",
    "\n",
    "        pred_nodes = diff_model(noised_nodes, t)\n",
    "\n",
    "        sum += diffusion_elbo(nodes, pred_nodes, params_mask, t, diff_model.noise_scheduler)\n",
    "    \n",
    "    nll = (sum / len(test_set)) * diff_model.max_timestep / 2 # Calculate sample mean\n",
    "    nll = nll / math.log(2) # Convert to bits\n",
    "    print(\"Negative Log-Likelihood: \", nll)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af9820",
   "metadata": {},
   "source": [
    "# Evaluate FID (Fr√©chet Inception Distance), Precision, and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7af6a16",
   "metadata": {},
   "source": [
    "CAD sketches are rendered to matplotlib figures as monochromatic images then converted to tensors, where FID, Precision, and Recall are calculated as ordinary image generation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd05a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_to_tensor(nodes : Tensor):\n",
    "    # Convert matplotlib figure to numpy array\n",
    "    figure = SketchDataset.render_graph(nodes)\n",
    "    figure.canvas.draw()\n",
    "    img_tensor = torch.frombuffer(figure.canvas.tostring_rgb(), dtype=torch.uint8).clone() # Copy buffer data into a tensor object\n",
    "    img_tensor = img_tensor.reshape(figure.canvas.get_width_height()[::-1] + (3,))\n",
    "    \n",
    "    # Add batch dimension and rearrange to (B, C, H, W)\n",
    "    img_tensor = img_tensor.permute(2, 0, 1).unsqueeze(0)\n",
    "    plt.close(figure)\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426c07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_loader = DataLoader(dataset = test_set[0:10_000][0], batch_size = BATCH_SIZE) # Create Dataloader only for nodes and not params mask\n",
    "\n",
    "    real_features = torch.zeros(10_000, 2048)\n",
    "    fake_features = torch.zeros(10_000, 2048)\n",
    "    fid = FrechetInceptionDistance(feature=2048).set_dtype(torch.float64).to(GPU)\n",
    "    fid.reset()\n",
    "\n",
    "    i = 1\n",
    "    for batch in tqdm(test_loader):\n",
    "        real_imgs = torch.vstack([figure_to_tensor(prims) for prims in batch]).to(GPU)\n",
    "        gens = diff_model.sample(batch.size(0))\n",
    "        gen_imgs = torch.vstack([figure_to_tensor(sample) for sample in gens]).to(GPU)\n",
    "\n",
    "        real_features[(i - 1) * BATCH_SIZE:i * BATCH_SIZE] = fid.inception(real_imgs)\n",
    "        fake_features[(i - 1) * BATCH_SIZE:i * BATCH_SIZE] = fid.inception(gen_imgs)\n",
    "        i = i + 1\n",
    "\n",
    "    torch.save({\"real\": real_features, \"fake\": fake_features}, OUTPUT_DIR + \"diff_inception_features.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9912d100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fid(real_features, fake_features):\n",
    "    # Calculate mean and covariance\n",
    "    mu1, sigma1 = real_features.mean(axis=0), np.cov(real_features, rowvar=False)\n",
    "    mu2, sigma2 = fake_features.mean(axis=0), np.cov(fake_features, rowvar=False)\n",
    "    \n",
    "    # Calculate FID\n",
    "    diff = mu1 - mu2\n",
    "    covmean = linalg.sqrtm(sigma1.dot(sigma2))\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    \n",
    "    fid = diff.dot(diff) + np.trace(sigma1 + sigma2 - 2*covmean)\n",
    "    return float(fid)\n",
    "\n",
    "def calculate_precision_recall(real_features, fake_features, k=3, threshold=0.95):\n",
    "    # Normalize features\n",
    "    real_features = real_features / np.linalg.norm(real_features, axis=1, keepdims=True)\n",
    "    fake_features = fake_features / np.linalg.norm(fake_features, axis=1, keepdims=True)\n",
    "    \n",
    "    # Calculate pairwise distances\n",
    "    real_distances = euclidean_distances(real_features, real_features)\n",
    "    fake_distances = euclidean_distances(fake_features, fake_features)\n",
    "    \n",
    "    # Get radii for each point (mean distance to k nearest neighbors)\n",
    "    def get_kth_nearest(distances, k):\n",
    "        # Sort distances for each point\n",
    "        nearest = np.partition(distances, k+1, axis=1)[:, 1:k+1]\n",
    "        return np.mean(nearest, axis=1)\n",
    "    \n",
    "    real_radii = get_kth_nearest(real_distances, k)\n",
    "    fake_radii = get_kth_nearest(fake_distances, k)\n",
    "    \n",
    "    # Calculate cross distances\n",
    "    cross_distances = euclidean_distances(real_features, fake_features)\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    precision = np.mean(np.min(cross_distances / real_radii[:, None], axis=0) < threshold)\n",
    "    recall = np.mean(np.min(cross_distances / fake_radii[None, :], axis=1) < threshold)\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "fid_score = calculate_fid(real_features.cpu().numpy(), fake_features.cpu().numpy())\n",
    "precision, recall = calculate_precision_recall(real_features.cpu().numpy(), fake_features.cpu().numpy())\n",
    "\n",
    "print(f\"FID Score: {fid_score:.2f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SketchDNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
