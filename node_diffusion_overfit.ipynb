{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor, device\n",
    "from torch.nn.utils.parametrizations import weight_norm\n",
    "from torch.optim.swa_utils import AveragedModel, get_ema_multi_avg_fn\n",
    "from torch.utils.data import random_split, TensorDataset, DataLoader\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from config import NODE_FEATURE_DIMENSION, EDGE_FEATURE_DIMENSION, MAX_NUM_PRIMITIVES, GRAPH_EMBEDDING_SIZE\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from dataset1 import SketchDataset\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "from IPython import display\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING HELPERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientParameterMonitor:\n",
    "    def __init__(self, model, writer : SummaryWriter, log_frequency=100):\n",
    "        self.model = model\n",
    "        self.log_frequency = log_frequency\n",
    "        self.step = 0\n",
    "        self.writer = writer\n",
    "\n",
    "    def update(self):\n",
    "        self.step += 1\n",
    "        if self.step % self.log_frequency == 0:\n",
    "            for name, param in self.model.named_parameters():\n",
    "                if \"node\" in name:\n",
    "                    if param.grad is not None:\n",
    "                        self._log_tensor_stats(f'{name}/grad', param.grad)\n",
    "                    self._log_tensor_stats(f'{name}/param', param.data)\n",
    "\n",
    "    def _log_tensor_stats(self, tag_prefix, tensor):\n",
    "        stats = self._get_tensor_stats(tensor)\n",
    "        for stat_name, value in stats.items():\n",
    "            self.writer.add_scalar(f'Monitor/{tag_prefix}/{stat_name}', value, self.step)\n",
    "\n",
    "    def _get_tensor_stats(self, tensor):\n",
    "        return {\n",
    "            'mean': tensor.mean().item(),\n",
    "            # 'std': tensor.std().item(),\n",
    "            'min': tensor.min().item(),\n",
    "            'max': tensor.max().item(),\n",
    "            # 'norm': torch.norm(tensor).item()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def batched_dot(a : Tensor, b : Tensor):\n",
    "    return (a * b).sum(dim = -1, keepdim = True)\n",
    "\n",
    "@torch.no_grad()\n",
    "def ToIscosceles(x : Tensor):\n",
    "    m = torch.tensor([[0.0, -1.0], [1.0, 0.0]], device = x.device).to(torch.double)\n",
    "\n",
    "    # To Iscosceles representation\n",
    "    y = x.clone().to(torch.double)\n",
    "    c = y[...,13:15] # torch.tensor([1.76, 2.21])\n",
    "    r = y[...,15,None] # torch.tensor([1.0])\n",
    "    alpha = y[...,16,None] * 2 * math.pi # torch.tensor([0.211])\n",
    "    beta = y[...,17,None] * 2 * math.pi # torch.tensor([0.987])\n",
    "\n",
    "    a = c + r * torch.cat([alpha.cos(), alpha.sin()], dim = -1)\n",
    "    b = c + r * torch.cat([beta.cos(), beta.sin()], dim = -1)\n",
    "    r_s = torch.where(batched_dot((a - b) @ m, a - c) > 0, -r, r)\n",
    "\n",
    "    y[...,13:15] = a\n",
    "    y[...,15:17] = b\n",
    "    y[...,17] = r_s.squeeze(-1)\n",
    "\n",
    "    return y.to(torch.float32)\n",
    "\n",
    "@torch.no_grad()\n",
    "def ToNaive(x : Tensor):\n",
    "    m = torch.tensor([[0.0, -1.0], [1.0, 0.0]], device = x.device).to(torch.double)\n",
    "\n",
    "    x = x.clone().to(torch.double)\n",
    "    a = x[...,13:15]\n",
    "    b = x[...,15:17]\n",
    "    r_s = x[...,17,None]\n",
    "\n",
    "    # To Naive representation\n",
    "    d = a - b\n",
    "\n",
    "    w = batched_dot(d, d).sqrt()\n",
    "    h = torch.sqrt(r_s ** 2 - w ** 2 / 4)\n",
    "\n",
    "    c = b + d / 2 + h / w * d @ m * r_s.sign()\n",
    "\n",
    "    al = (a - c) / r_s.abs()\n",
    "    al = (torch.atan2(al[...,1], al[...,0]).unsqueeze(-1) % (2 * math.pi)) / (2 * math.pi)\n",
    "    be = (b - c) / r_s.abs()\n",
    "    be = (torch.atan2(be[...,1], be[...,0]).unsqueeze(-1) % (2 * math.pi)) / (2 * math.pi)\n",
    "\n",
    "    x[...,13:18] = torch.cat([c, torch.abs(r_s), al, be], dim = -1)\n",
    "    x[x.isnan()] = 0\n",
    "    return x.to(torch.float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineNoiseScheduler(nn.Module):\n",
    "  def __init__(self, max_timestep : int, device : torch.device):\n",
    "    super().__init__()\n",
    "    self.device = device\n",
    "    self.max_timestep = max_timestep\n",
    "    self.offset = .008 # Fixed offset to improve noise prediction at early timesteps\n",
    "\n",
    "    # Cosine Beta Schedule Formula: https://arxiv.org/abs/2102.09672\n",
    "    self.a_bar = torch.cos((torch.linspace(0, 1, self.max_timestep + 1).to(self.device) + self.offset) * 0.5 * math.pi / (1 + self.offset)) ** 2\n",
    "    self.a_bar = self.a_bar / self.a_bar[0]\n",
    "    self.a_bar = self.a_bar.clamp(min = 0.001, max = 0.999)\n",
    "  \n",
    "  def forward(self, nodes : Tensor, timestep : Tensor):\n",
    "    ''' Apply noise to graph '''\n",
    "    noisy_nodes = torch.zeros(size = nodes.size(), device = nodes.device)\n",
    "    added_noise = torch.zeros(size = nodes.size(), device = nodes.device)\n",
    "    \n",
    "    # IsConstructible noise\n",
    "    noisy_nodes[...,0:2], added_noise[...,0:2] = self.apply_discrete_noise(nodes[...,0:2], timestep)\n",
    "    # Primitive Types noise\n",
    "    noisy_nodes[...,2:7], added_noise[...,2:7] = self.apply_discrete_noise(nodes[...,2:7], timestep)\n",
    "    # Primitive parameters noise\n",
    "    noisy_nodes[...,7:], added_noise[...,7:] = self.apply_continuous_noise(nodes[...,7:], timestep)\n",
    "    \n",
    "    return noisy_nodes, added_noise\n",
    "  \n",
    "  def sample_latent(self, batch_size : int) -> Tensor:\n",
    "    noisy_nodes = torch.zeros(size = (batch_size, 24, 21), device = self.device)\n",
    "\n",
    "    # IsConstructible noise\n",
    "    uniform_noise = torch.rand_like(noisy_nodes[...,0:2])\n",
    "    gumbel_noise = -torch.log(-torch.log(uniform_noise))\n",
    "    noisy_nodes[...,0:2] = gumbel_noise.softmax(dim = -1)\n",
    "    # Primitive Types noise\n",
    "    uniform_noise = torch.rand_like(noisy_nodes[...,2:7])\n",
    "    gumbel_noise = -torch.log(-torch.log(uniform_noise))\n",
    "    noisy_nodes[...,2:7] = gumbel_noise.softmax(dim = -1)\n",
    "    # Primitive parameters noise\n",
    "    gaussian_noise = torch.randn_like(noisy_nodes[...,7:])\n",
    "    noisy_nodes[...,7:] = gaussian_noise\n",
    "    \n",
    "    return noisy_nodes\n",
    "  \n",
    "  def apply_continuous_noise(self, params : Tensor, timestep : Tensor | int) -> Tensor:\n",
    "    if type(timestep) is int:\n",
    "      if timestep == 0: \n",
    "        return params, 0 \n",
    "      assert timestep > 0 \n",
    "      assert timestep < self.max_timestep \n",
    "      timestep = [timestep]\n",
    "\n",
    "    a = torch.sqrt(self.a_bar[timestep, None, None])\n",
    "    b = torch.sqrt(1 - self.a_bar[timestep, None, None])\n",
    "\n",
    "    noise = torch.randn_like(params)\n",
    "    return a * params + b * noise, noise\n",
    "  \n",
    "  def continuous_posterior_step(self, pred_params : Tensor, curr_params : Tensor, timestep : Tensor | int) -> Tensor:\n",
    "    if type(timestep) is int:\n",
    "      if timestep == 0: \n",
    "        return pred_params\n",
    "      assert timestep > 0 \n",
    "      assert timestep < self.max_timestep \n",
    "      timestep = torch.tensor(data = [timestep], device = pred_params.device)\n",
    "\n",
    "    b_bar = 1 - self.a_bar[timestep, None, None]\n",
    "    sqrt_prev_b_bar = torch.sqrt(1 - self.a_bar[timestep - 1, None, None])\n",
    "    prev_a_bar = self.a_bar[timestep - 1, None, None]\n",
    "    curr_a = self.a_bar[timestep, None, None] / self.a_bar[timestep - 1, None, None]\n",
    "\n",
    "    mean = (1 - curr_a) * torch.sqrt(prev_a_bar) * pred_params + torch.sqrt(curr_a) * (1 - prev_a_bar) * curr_params\n",
    "    mean = mean / b_bar \n",
    "\n",
    "    noise = torch.randn_like(pred_params)\n",
    "    return mean + sqrt_prev_b_bar * noise #, noise\n",
    "  \n",
    "  def apply_discrete_noise(self, params : Tensor, timestep : Tensor | int) -> Tensor:\n",
    "    if type(timestep) is int:\n",
    "      if timestep == 0: \n",
    "        return params, 0 \n",
    "      assert timestep > 0\n",
    "      assert timestep < self.max_timestep\n",
    "      timestep = [timestep]\n",
    "      \n",
    "    a = self.a_bar[timestep, None, None]\n",
    "\n",
    "    D = params.size(-1)\n",
    "    noise = torch.log(-torch.log(torch.rand_like(params).clamp(min = 1e-10, max = 1 - 1e-10))) # Gumbel Noise\n",
    "    return torch.softmax(torch.log(a * params + (1 - a) / D) + noise, dim = -1), noise\n",
    "  \n",
    "  def discrete_posterior_step(self, pred_params : Tensor, curr_params : Tensor, timestep : Tensor | int) -> Tensor:\n",
    "    if type(timestep) is int:\n",
    "      if timestep == 0: \n",
    "        return pred_params\n",
    "      assert timestep > 0\n",
    "      assert timestep < self.max_timestep\n",
    "      timestep = torch.tensor(data = [timestep], device = pred_params.device)\n",
    "      \n",
    "    D = pred_params.size(-1)\n",
    "    a_bar = self.a_bar[timestep, None, None]\n",
    "    prev_a_bar = self.a_bar[timestep - 1, None, None]\n",
    "    curr_a = self.a_bar[timestep, None, None] / self.a_bar[timestep - 1, None, None]\n",
    "    Q_bar = a_bar * torch.eye(D, device = pred_params.device) + (1 - a_bar) / D\n",
    "    prev_Q_bar = prev_a_bar * torch.eye(D, device = pred_params.device) + (1 - prev_a_bar) / D\n",
    "    curr_Q = curr_a * torch.eye(D, device = pred_params.device) + (1 - curr_a) / D\n",
    "\n",
    "    xt = F.one_hot(torch.argmax(curr_params, dim = -1), D).to(pred_params.device).float()\n",
    "    qt = xt @ curr_Q.permute(0, 2, 1) # (b, m, d), since xt is onehot we are plucking out rows corresponding to p(x_t = class | x_(t-1))\n",
    "    qt_bar = xt @ Q_bar.permute(0, 2, 1) # (b, m, d), since xt is onehot we are plucking out rows corresponding to p(x_t = class | x_0)\n",
    "    q = qt.unsqueeze(2) / qt_bar.unsqueeze(3) # (b, m, d, d), perform an outer product so element at (b, m, i, j) = p(x_t = class | x_(t-1) = j) / p(x_t = class | x_0 = i)\n",
    "    q = q * prev_Q_bar.unsqueeze(1) # (b, m, d, d), broadcast multiply so element at (b, m, i, j) = p(x_t = class | x_(t-1) = j) * p(x_(t-1) = j | x_0 = i) / p(x_t = class | x_0 = i)\n",
    "    pred_class_probs = pred_params.unsqueeze(-2) # (b, n, 1, d), make probs into row vector\n",
    "    posterior_distribution = pred_class_probs @ q # (b, n, 1, d), batched vector-matrix multiply\n",
    "    posterior_distribution = posterior_distribution.squeeze(-2) # (b, n, d)\n",
    "\n",
    "    noise = torch.log(-torch.log(torch.rand_like(pred_params).clamp(min = 1e-10, max = 1 - 1e-10))) # Gumbel Noise\n",
    "    return torch.softmax(torch.log(posterior_distribution) + noise, dim = -1) #, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbedder(nn.Module):\n",
    "  def __init__(self, max_timestep : int, embedding_dimension : int, device : torch.device):\n",
    "    super().__init__()\n",
    "    self.device = device\n",
    "    self.embed_dim = embedding_dimension\n",
    "    self.max_steps = max_timestep\n",
    "    # self.max_timestep = max_timestep\n",
    "    \n",
    "    # self.time_embs = nn.Embedding(num_embeddings = max_timestep, embedding_dim = embedding_dimension, device = device)\n",
    "    timesteps = torch.arange(self.max_steps, device = self.device).unsqueeze(1) # num_timesteps x 1\n",
    "    scales = torch.exp(torch.arange(0, self.embed_dim, 2, device = self.device) * (-math.log(10000.0) / self.embed_dim)).unsqueeze(0) # 1 x (embedding_dimension // 2)\n",
    "    self.time_embs = torch.zeros(self.max_steps, self.embed_dim, device = self.device) # num_timesteps x embedding_dimension\n",
    "    self.time_embs[:, 0::2] = torch.sin(timesteps * scales) # fill even columns with sin(timestep * 1000^-(2*i/embedding_dimension))\n",
    "    self.time_embs[:, 1::2] = torch.cos(timesteps * scales) # fill odd columns with cos(timestep * 1000^-(2*i/embedding_dimension))\n",
    "      \n",
    "  def forward(self, timestep : Tensor):\n",
    "    return self.time_embs[timestep] # batch_size x embedding_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinuisodalEncoding(nn.Module):\n",
    "  def __init__(self, max_length : int, embedding_dimension : int, device : torch.device):\n",
    "    super().__init__()\n",
    "    self.device = device\n",
    "    self.embed_dim = embedding_dimension\n",
    "    \n",
    "    # self.time_embs = nn.Embedding(num_embeddings = max_timestep, embedding_dim = embedding_dimension, device = device)\n",
    "    steps = torch.arange(max_length, device = self.device).unsqueeze(1) # num_timesteps x 1\n",
    "    scales = torch.exp(torch.arange(0, self.embed_dim, 2, device = self.device) * (-math.log(10000.0) / self.embed_dim)).unsqueeze(0) # 1 x (embedding_dimension // 2)\n",
    "    self.embs = torch.zeros(max_length, self.embed_dim, device = self.device) # num_timesteps x embedding_dimension\n",
    "    self.embs[:, 0::2] = torch.sin(steps * scales) # fill even columns with sin(timestep * 1000^-(2*i/embedding_dimension))\n",
    "    self.embs[:, 1::2] = torch.cos(steps * scales) # fill odd columns with cos(timestep * 1000^-(2*i/embedding_dimension))\n",
    "      \n",
    "  def forward(self, step : Tensor):\n",
    "    return self.embs[step] # batch_size x embedding_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MPDiffusionModel(nn.Module):\n",
    "#     def __init__(self, node_dim, node_hidden_dim, cond_hidden_dim, num_heads, num_tf_layers, num_checkpoints, max_timestep, device: device):\n",
    "#         super().__init__()\n",
    "#         self.num_checkpoints = num_checkpoints\n",
    "\n",
    "#         self.time_embedder = MPFourier(cond_hidden_dim, device)\n",
    "\n",
    "#         # Input MLP layers\n",
    "#         self.mlp_in_nodes = nn.Sequential(\n",
    "#             MPLinear(in_features = node_dim, out_features = node_hidden_dim, device = device),\n",
    "#             MPSiLU(),\n",
    "#             MPLinear(in_features = node_hidden_dim, out_features = node_hidden_dim, device = device),\n",
    "#             MPSiLU()\n",
    "#         )\n",
    "\n",
    "#         self.mlp_in_conds = nn.Sequential(\n",
    "#             MPLinear(in_features = cond_hidden_dim, out_features = cond_hidden_dim, device = device),\n",
    "#             MPSiLU(),\n",
    "#             MPLinear(in_features = cond_hidden_dim, out_features = cond_hidden_dim, device = device),\n",
    "#             MPSiLU()\n",
    "#         )\n",
    "\n",
    "#         # Transformer Layers with Graph Attention Network\n",
    "#         self.block_layers = nn.ModuleList([\n",
    "#             TransformerLayer(\n",
    "#                 node_dim = node_hidden_dim,\n",
    "#                 cond_dim = cond_hidden_dim,\n",
    "#                 num_heads = num_heads,\n",
    "#                 device = device\n",
    "#             ) for _ in range(num_tf_layers)\n",
    "#         ])\n",
    "        \n",
    "#         # self.norm = Normalization(node_dim = node_hidden_dim, device = device)\n",
    "#         # Output MLP layers\n",
    "#         self.type_gain = nn.Parameter(torch.randn(size = (1,), device = device))\n",
    "#         self.param_gain = nn.Parameter(torch.randn(size = (1,), device = device))\n",
    "#         self.mlp_out_node_types = MPLinear(in_features = node_hidden_dim, out_features = 6, device = device)\n",
    "#         self.mlp_out_node_params = MPLinear(in_features = node_hidden_dim, out_features = 14, device = device)\n",
    "\n",
    "#     def forward(self, nodes : Tensor, sdev : Tensor):\n",
    "#         nodes = self.mlp_in_nodes(nodes)     # shape: (batch_size, num_nodes, node_hidden_dim)\n",
    "#         conds = self.time_embedder(sdev) # shape: (batch_size, cond_hidden_dim)\n",
    "#         # conds = self.mlp_in_conds(conds)     # shape: (batch_size, cond_hidden_dim)\n",
    "\n",
    "#         checkpoints = self.num_checkpoints\n",
    "#         for layer in self.block_layers:\n",
    "#             nodes = layer(nodes, conds) # shape: (batch_size, num_nodes, node_hidden_dim) ; shape: (batch_size, num_nodes, num_nodes, edge_hidden_dim)\n",
    "#             checkpoints = checkpoints - 1\n",
    "\n",
    "#         # nodes = self.norm(nodes)\n",
    "#         nodes = mp_cat(self.mlp_out_node_types(nodes, self.type_gain), self.mlp_out_node_params(nodes, self.param_gain), dim = -1) # shape: (batch_size, num_nodes, node_dim)\n",
    "\n",
    "#         return nodes\n",
    "\n",
    "# class TransformerLayer(nn.Module):\n",
    "#     def __init__(self, node_dim: int, cond_dim: int, num_heads: int, device: device):\n",
    "#         super().__init__()\n",
    "#         self.node_dim = node_dim\n",
    "\n",
    "#         # Normalization\n",
    "#         # self.norm_in = Normalization(node_dim = node_dim, device = device)\n",
    "\n",
    "#         # Attention Layer\n",
    "#         self.attention_heads = MultiHeadAttention(\n",
    "#             node_dim = node_dim,\n",
    "#             num_heads = num_heads,\n",
    "#             device = device\n",
    "#         )\n",
    "\n",
    "#         # Normalization\n",
    "#         # self.norm_attn = Normalization(node_dim = node_dim, device = device)\n",
    "\n",
    "#         # Node and edge MLPs\n",
    "#         self.mlp_nodes = nn.Sequential(\n",
    "#             MPLinear(in_features = node_dim, out_features = node_dim, device = device),\n",
    "#             MPSiLU(),\n",
    "#             MPLinear(in_features = node_dim, out_features = node_dim, device = device),\n",
    "#             # MPSiLU()\n",
    "#         )\n",
    "\n",
    "#         # Conditioning\n",
    "#         self.film_in = FiLM(node_dim = node_dim, cond_dim = cond_dim, device = device)\n",
    "#         self.film_attn = FiLM(node_dim = node_dim, cond_dim = cond_dim, device = device)\n",
    "#         # self.mul = nn.Linear(in_features = cond_dim, out_features = 2 * (node_dim + edge_dim), device = device)\n",
    "\n",
    "#     def forward(self, nodes : Tensor, conds : Tensor) -> Tensor:\n",
    "#         # Attention\n",
    "#         nodes = self.attention_heads(self.film_in(nodes, conds)) + nodes\n",
    "#         # MLP\n",
    "#         nodes = self.mlp_nodes(self.film_attn(mp_silu(nodes), conds)) + nodes\n",
    "\n",
    "#         return mp_silu(nodes)\n",
    "\n",
    "# class MultiHeadAttention(nn.Module):\n",
    "#     def __init__(self, node_dim : int, num_heads : int, device : torch.device):\n",
    "#         super().__init__()\n",
    "#         self.node_dim = node_dim\n",
    "#         self.num_heads = num_heads\n",
    "#         self.attn_dim = node_dim // num_heads\n",
    "\n",
    "#         self.lin_qkv = MPLinear(in_features = self.node_dim, out_features = 3 * self.node_dim, device = device)\n",
    "\n",
    "#         self.lin_nodes_out = MPLinear(in_features = self.node_dim, out_features = self.node_dim, device = device)                     \n",
    "\n",
    "#     def forward(self, nodes : Tensor) -> Tensor:\n",
    "#         batch_size, num_nodes, _ = nodes.size()\n",
    "        \n",
    "#         queries, keys, values = self.lin_qkv(nodes).chunk(chunks = 3, dim = -1)\n",
    "\n",
    "#         queries = queries.reshape(batch_size, num_nodes, self.num_heads, -1).permute(0, 2, 1, 3) # batch_size x num_heads x num_nodes x attn_dim\n",
    "#         queries = normalize(queries)\n",
    "#         keys = keys.reshape(batch_size, num_nodes, self.num_heads, -1).permute(0, 2, 1, 3) # batch_size x num_heads x num_nodes x attn_dim\n",
    "#         keys = normalize(keys)\n",
    "#         values = values.reshape(batch_size, num_nodes, self.num_heads, -1).permute(0, 2, 1, 3) # batch_size x num_heads x num_nodes x attn_dim\n",
    "#         values = normalize(values)\n",
    "\n",
    "#         weighted_values = F.scaled_dot_product_attention(query = queries, key = keys, value = values).permute(0, 2, 1, 3).flatten(-2)\n",
    "\n",
    "#         return self.lin_nodes_out(weighted_values)\n",
    "\n",
    "# class Normalization(nn.Module):\n",
    "#     def __init__(self, node_dim: int, device: torch.device):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.norm_nodes = nn.InstanceNorm1d(num_features = node_dim, device = device)\n",
    "\n",
    "#     def forward(self, nodes : Tensor) -> Tensor:\n",
    "#         return self.norm_nodes(nodes.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "\n",
    "# class FiLM(nn.Module):\n",
    "#     def __init__(self, node_dim : int, cond_dim : int, device : device):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.lin_node_mul = MPLinear(in_features = cond_dim, out_features = node_dim, device = device)\n",
    "#         self.gain = nn.Parameter(torch.randn(size = (1,), device = device))\n",
    "    \n",
    "#     def forward(self, node : Tensor, cond : Tensor) -> Tensor:\n",
    "#         node_mul = self.lin_node_mul(cond, self.gain)\n",
    "\n",
    "#         return node_mul * node + node\n",
    "    \n",
    "# #----------------------------------------------------------------------------\n",
    "# # Normalize given tensor to unit magnitude with respect to the given\n",
    "# # dimensions. Default = all dimensions except the first.\n",
    "\n",
    "# def normalize(x, dim=None, eps=1e-4):\n",
    "#     if dim is None:\n",
    "#         dim = list(range(1, x.ndim))\n",
    "#     norm = torch.linalg.vector_norm(x, dim=dim, keepdim=True, dtype=torch.float32)\n",
    "#     norm = torch.add(eps, norm, alpha=np.sqrt(norm.numel() / x.numel()))\n",
    "#     return x / norm.to(x.dtype)\n",
    "\n",
    "# #----------------------------------------------------------------------------\n",
    "# # Magnitude-preserving SiLU (Equation 81).\n",
    "\n",
    "# def mp_silu(x):\n",
    "#     return torch.nn.functional.silu(x) / 0.596\n",
    "\n",
    "# class MPSiLU(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "    \n",
    "#     def forward(self, nodes : Tensor) -> Tensor:\n",
    "#         return mp_silu(nodes)\n",
    "\n",
    "# #----------------------------------------------------------------------------\n",
    "# # Magnitude-preserving sum (Equation 88).\n",
    "\n",
    "# def mp_sum(a, b, t=0.5):\n",
    "#     return a.lerp(b, t) / np.sqrt((1 - t) ** 2 + t ** 2)\n",
    "\n",
    "# #----------------------------------------------------------------------------\n",
    "# # Magnitude-preserving concatenation (Equation 103).\n",
    "\n",
    "# def mp_cat(a, b, dim=1, t=0.5):\n",
    "#     Na = a.shape[dim]\n",
    "#     Nb = b.shape[dim]\n",
    "#     C = np.sqrt((Na + Nb) / ((1 - t) ** 2 + t ** 2))\n",
    "#     wa = C / np.sqrt(Na) * (1 - t)\n",
    "#     wb = C / np.sqrt(Nb) * t\n",
    "#     return torch.cat([wa * a , wb * b], dim=dim)\n",
    "\n",
    "# #----------------------------------------------------------------------------\n",
    "# # Magnitude-preserving Fourier features (Equation 75).\n",
    "\n",
    "# class MPFourier(torch.nn.Module):\n",
    "#     def __init__(self, num_channels, device):\n",
    "#         super().__init__()\n",
    "#         self.register_buffer('freqs', 2 * np.pi * torch.randn(num_channels, device = device))\n",
    "#         self.register_buffer('phases', 2 * np.pi * torch.rand(num_channels, device = device))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         y = x.to(torch.float32)\n",
    "#         y = y.ger(self.freqs.to(torch.float32))\n",
    "#         y = y + self.phases.to(torch.float32)\n",
    "#         y = y.cos() * np.sqrt(2)\n",
    "#         return y.to(x.dtype)\n",
    "\n",
    "# #----------------------------------------------------------------------------\n",
    "# # Magnitude-preserving convolution or fully-connected layer (Equation 47)\n",
    "# # with force weight normalization (Equation 66).\n",
    "\n",
    "# class MPLinear(torch.nn.Module):\n",
    "#     def __init__(self, in_features, out_features, device):\n",
    "#         super().__init__()\n",
    "#         self.weight = torch.nn.Parameter(torch.randn(size = (in_features, out_features), device = device))\n",
    "\n",
    "#     def forward(self, x, gain=1):\n",
    "#         w = self.weight.to(torch.float32)\n",
    "#         if self.training:\n",
    "#             with torch.no_grad():\n",
    "#                 self.weight.copy_(normalize(w)) # forced weight normalization\n",
    "#         w = normalize(w) # traditional weight normalization\n",
    "#         w = w * (gain / np.sqrt(w[0].numel())) # magnitude-preserving scaling\n",
    "#         w = w.to(x.dtype)\n",
    "        \n",
    "#         return x @ w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DiffusionModel(nn.Module):\n",
    "#     def __init__(self, node_dim, node_hidden_dim, cond_hidden_dim, num_heads, num_tf_layers, num_checkpoints, max_timestep, device: device):\n",
    "#         super().__init__()\n",
    "#         self.num_checkpoints = num_checkpoints\n",
    "\n",
    "#         self.time_embedder = TimeEmbedder(max_timestep, cond_hidden_dim, device)\n",
    "#         self.pos_embedder = SinuisodalEncoding(max_length = 24, embedding_dimension = node_hidden_dim, device = device)\n",
    "\n",
    "#         # Input MLP layers\n",
    "#         self.mlp_in_nodes = nn.Sequential(\n",
    "#             nn.Linear(in_features = node_dim, out_features = node_hidden_dim, device = device),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             nn.Linear(in_features = node_hidden_dim, out_features = node_hidden_dim, device = device),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#         )\n",
    "\n",
    "#         self.mlp_in_conds = nn.Sequential(\n",
    "#             nn.Linear(in_features = cond_hidden_dim, out_features = cond_hidden_dim, device = device),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             nn.Linear(in_features = cond_hidden_dim, out_features = cond_hidden_dim, device = device),\n",
    "#             nn.LeakyReLU(0.1)\n",
    "#         )\n",
    "\n",
    "#         # Transformer Layers with Graph Attention Network\n",
    "#         self.block_layers = nn.ModuleList([\n",
    "#             TransformerLayer(\n",
    "#                 node_dim = node_hidden_dim,\n",
    "#                 cond_dim = cond_hidden_dim,\n",
    "#                 num_heads = num_heads,\n",
    "#                 device = device\n",
    "#             ) for _ in range(num_tf_layers)\n",
    "#         ])\n",
    "        \n",
    "#         # Output MLP layers\n",
    "#         self.mlp_out_nodes = nn.Sequential(\n",
    "#             nn.Linear(in_features = node_hidden_dim, out_features = node_hidden_dim, device = device),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             nn.Linear(in_features = node_hidden_dim, out_features = node_dim, device = device)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, nodes : Tensor, timestep : Tensor):\n",
    "#         nodes = self.mlp_in_nodes(nodes)     # shape: (batch_size, num_nodes, node_hidden_dim)\n",
    "#         # nodes = nodes + self.pos_embedder.embs\n",
    "#         conds = self.time_embedder(timestep) # shape: (batch_size, cond_hidden_dim)\n",
    "#         # conds = self.mlp_in_conds(conds)     # shape: (batch_size, cond_hidden_dim)\n",
    "\n",
    "#         # nodes = nodes + conds.unsqueeze(1)\n",
    "#         # edges = edges + conds.unsqueeze(1).unsqueeze(1)\n",
    "#         checkpoints = self.num_checkpoints\n",
    "#         for layer in self.block_layers:\n",
    "#             nodes = layer(nodes, conds) # shape: (batch_size, num_nodes, node_hidden_dim) ; shape: (batch_size, num_nodes, num_nodes, edge_hidden_dim)\n",
    "#             checkpoints = checkpoints - 1\n",
    "\n",
    "#         nodes = self.mlp_out_nodes(nodes) # shape: (batch_size, num_nodes, node_dim)\n",
    "\n",
    "#         return nodes\n",
    "\n",
    "# class TransformerLayer(nn.Module):\n",
    "#     def __init__(self, node_dim: int, cond_dim: int, num_heads: int, device: device):\n",
    "#         super().__init__()\n",
    "#         self.node_dim = node_dim\n",
    "\n",
    "#         # Normalization\n",
    "#         self.norm_in = nn.Sequential(\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             Normalization(node_dim = node_dim, device = device),\n",
    "#         )\n",
    "\n",
    "#         # Attention Layer\n",
    "#         self.attention_heads = MultiHeadDotAttention(node_dim = node_dim, num_heads = num_heads, device = device)\n",
    "\n",
    "#         # Normalization\n",
    "#         self.norm_attn = nn.Sequential(\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             Normalization(node_dim = node_dim, device = device),\n",
    "#         )\n",
    "\n",
    "#         # Node and edge MLPs\n",
    "#         self.mlp_nodes = nn.Sequential(\n",
    "#             nn.Linear(in_features = node_dim, out_features = node_dim, device = device),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             nn.Linear(in_features = node_dim, out_features = node_dim, device = device),\n",
    "#             # nn.LeakyReLU(0.1),\n",
    "#         )\n",
    "\n",
    "#         # # Conditioning\n",
    "#         # self.film_in = FiLM(node_dim = node_dim, cond_dim = cond_dim, device = device)\n",
    "#         # self.film_attn = FiLM(node_dim = node_dim, cond_dim = cond_dim, device = device)\n",
    "#         # self.mul = nn.Linear(in_features = cond_dim, out_features = 2 * (node_dim + edge_dim), device = device)\n",
    "#         self.lin_cond = nn.Linear(in_features = cond_dim, out_features = 4 * node_dim, device = device)\n",
    "\n",
    "#     def forward(self, nodes : Tensor, conds : Tensor) -> Tensor:\n",
    "#         mul_in, add_in, mul_attn, add_attn = self.lin_cond(conds.unsqueeze(1)).chunk(chunks = 4, dim = -1)\n",
    "#         # Attention\n",
    "#         nodes = self.attention_heads(nodes) + nodes\n",
    "#         nodes = self.norm_in(nodes) * mul_in + add_in\n",
    "#         # MLP\n",
    "#         nodes = self.mlp_nodes(nodes) + nodes\n",
    "#         nodes = self.norm_attn(nodes) * mul_attn + add_attn\n",
    "\n",
    "#         # # Attention\n",
    "#         # nodes = self.attention_heads(self.film_in(self.norm_in(nodes), conds)) + nodes\n",
    "#         # # MLP\n",
    "#         # nodes = self.mlp_nodes(self.film_attn(self.norm_attn(nodes), conds)) + nodes\n",
    "\n",
    "#         return nodes\n",
    "\n",
    "# class MultiHeadMLPAttention(nn.Module):\n",
    "#     def __init__(self, node_dim : int, num_heads : int, device : torch.device):\n",
    "#         super().__init__()\n",
    "#         self.num_heads = num_heads\n",
    "#         self.attn_dim = 32\n",
    "\n",
    "#         self.lin_vw = nn.Sequential(\n",
    "#             nn.Linear(in_features = 2 * node_dim, out_features = 2 * node_dim, device = device),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             nn.Linear(in_features = 2 * node_dim, out_features = num_heads * self.attn_dim + num_heads, device = device)\n",
    "#         )\n",
    "\n",
    "#         self.lin_nodes_out = nn.Linear(in_features = num_heads * self.attn_dim, out_features = node_dim, device = device)                \n",
    "\n",
    "#     def forward(self, nodes : Tensor) -> Tensor:\n",
    "#         b, n, d = nodes.size()\n",
    "#         h = self.num_heads\n",
    "        \n",
    "#         features = torch.cat([nodes.unsqueeze(1).expand(-1, n, -1, -1), nodes.unsqueeze(2).expand(-1, -1, n, -1)], dim = -1)\n",
    "#         v, w = self.lin_vw(features).split([self.num_heads * self.attn_dim, self.num_heads], dim = -1)\n",
    "#         v = v.reshape(b, n, n, h, -1)\n",
    "#         w = w.reshape(b, n, n, h, -1).softmax(dim = 2)\n",
    "#         # w = (w * w / w.size(-1)).sum(dim = -1, keepdim = True).softmax(dim = 2)\n",
    "#         weighted_values = (w * v).sum(dim = 2).flatten(start_dim = 2)\n",
    "\n",
    "#         return self.lin_nodes_out(weighted_values)\n",
    "    \n",
    "# class MultiHeadDotAttention(nn.Module):\n",
    "#     def __init__(self, node_dim : int, num_heads : int, device : torch.device):\n",
    "#         super().__init__()\n",
    "#         self.node_dim = node_dim\n",
    "#         self.num_heads = num_heads\n",
    "#         attn_dim = 64\n",
    "\n",
    "#         self.lin_qkv = nn.Linear(in_features = self.node_dim, out_features = 3 * attn_dim * num_heads, device = device)\n",
    "\n",
    "#         self.lin_nodes_out = nn.Linear(in_features = attn_dim * num_heads, out_features = self.node_dim, device = device)                     \n",
    "\n",
    "#     def forward(self, nodes : Tensor) -> Tensor:\n",
    "#         batch_size, num_nodes, _ = nodes.size()\n",
    "        \n",
    "#         queries, keys, values = self.lin_qkv(nodes).chunk(chunks = 3, dim = -1)\n",
    "\n",
    "#         queries = queries.reshape(batch_size, num_nodes, self.num_heads, -1).permute(0, 2, 1, 3) # batch_size x num_heads x num_nodes x attn_dim\n",
    "#         keys = keys.reshape(batch_size, num_nodes, self.num_heads, -1).permute(0, 2, 1, 3)       # batch_size x num_heads x num_nodes x attn_dim\n",
    "#         values = values.reshape(batch_size, num_nodes, self.num_heads, -1).permute(0, 2, 1, 3)   # batch_size x num_heads x num_nodes x attn_dim\n",
    "\n",
    "#         weighted_values = F.scaled_dot_product_attention(query = queries, key = keys, value = values).permute(0, 2, 1, 3).flatten(start_dim = 2)\n",
    "\n",
    "#         return self.lin_nodes_out(weighted_values)\n",
    "\n",
    "# class Normalization(nn.Module):\n",
    "#     def __init__(self, node_dim: int, device: device):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         # self.norm_nodes = nn.InstanceNorm1d(num_features = node_dim, device = device)\n",
    "#         # self.norm_nodes = nn.BatchNorm1d(num_features = node_dim, affine = False, device = device)\n",
    "#         self.norm_nodes = nn.LayerNorm(normalized_shape = node_dim, elementwise_affine = False, device = device)\n",
    "\n",
    "#     def forward(self, nodes : Tensor) -> Tensor:\n",
    "#         # return self.norm_nodes(nodes.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "#         return self.norm_nodes(nodes)\n",
    "\n",
    "# class FiLM(nn.Module):\n",
    "#     def __init__(self, node_dim : int, cond_dim : int, device : device):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.lin_node = nn.Linear(in_features = cond_dim, out_features = 2 * node_dim, device = device)\n",
    "    \n",
    "#     def forward(self, node : Tensor, cond : Tensor) -> Tensor:\n",
    "#         node_mul, node_add = self.lin_node(cond).unsqueeze(1).chunk(chunks = 2, dim = -1)\n",
    "\n",
    "#         return node_mul * node + node_add + node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DiffusionModel(nn.Module):\n",
    "#     def __init__(self, node_dim, node_hidden_dim, cond_hidden_dim, num_heads, num_tf_layers, num_checkpoints, max_timestep, device: device):\n",
    "#         super().__init__()\n",
    "#         self.num_checkpoints = num_checkpoints\n",
    "\n",
    "#         self.time_embedder = TimeEmbedder(max_timestep, cond_hidden_dim, device)\n",
    "#         # self.pos_embedder = SinuisodalEncoding(max_length = 24, embedding_dimension = node_hidden_dim, device = device)\n",
    "\n",
    "#         # Input MLP layers\n",
    "#         self.mlp_in_nodes = nn.Sequential(\n",
    "#             nn.Linear(in_features = node_dim, out_features = node_hidden_dim, device = device),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             nn.Linear(in_features = node_hidden_dim, out_features = node_hidden_dim, device = device),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#         )\n",
    "\n",
    "#         self.mlp_in_conds = nn.Sequential(\n",
    "#             nn.Linear(in_features = cond_hidden_dim, out_features = cond_hidden_dim, device = device),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             nn.Linear(in_features = cond_hidden_dim, out_features = cond_hidden_dim, device = device),\n",
    "#             nn.LeakyReLU(0.1)\n",
    "#         )\n",
    "\n",
    "#         # Transformer Layers with Graph Attention Network\n",
    "#         self.block_layers = nn.ModuleList([\n",
    "#             TransformerLayer(\n",
    "#                 node_dim = node_hidden_dim,\n",
    "#                 cond_dim = cond_hidden_dim,\n",
    "#                 num_heads = num_heads,\n",
    "#                 device = device\n",
    "#             ) for _ in range(num_tf_layers)\n",
    "#         ])\n",
    "        \n",
    "#         # Output MLP layers\n",
    "#         self.mlp_out_nodes = nn.Sequential(\n",
    "#             nn.Linear(in_features = node_hidden_dim, out_features = node_hidden_dim, device = device),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             nn.Linear(in_features = node_hidden_dim, out_features = node_dim, device = device)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, nodes : Tensor, timestep : Tensor):\n",
    "#         nodes = self.mlp_in_nodes(nodes)     # shape: (batch_size, num_nodes, node_hidden_dim)\n",
    "#         # nodes = nodes + self.pos_embedder.embs\n",
    "#         conds = self.time_embedder(timestep) # shape: (batch_size, cond_hidden_dim)\n",
    "#         conds = self.mlp_in_conds(conds)     # shape: (batch_size, cond_hidden_dim)\n",
    "\n",
    "#         # nodes = nodes + conds.unsqueeze(1)\n",
    "#         # edges = edges + conds.unsqueeze(1).unsqueeze(1)\n",
    "#         checkpoints = self.num_checkpoints\n",
    "#         for layer in self.block_layers:\n",
    "#             nodes = layer(nodes, conds) # shape: (batch_size, num_nodes, node_hidden_dim) ; shape: (batch_size, num_nodes, num_nodes, edge_hidden_dim)\n",
    "#             checkpoints = checkpoints - 1\n",
    "\n",
    "#         nodes = self.mlp_out_nodes(nodes) # shape: (batch_size, num_nodes, node_dim)\n",
    "\n",
    "#         return nodes\n",
    "\n",
    "# class TransformerLayer(nn.Module):\n",
    "#     def __init__(self, node_dim: int, cond_dim: int, num_heads: int, device: device):\n",
    "#         super().__init__()\n",
    "#         self.node_dim = node_dim\n",
    "\n",
    "#         # Normalization\n",
    "#         self.norm_in = nn.Sequential(\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             Normalization(node_dim = node_dim, device = device),\n",
    "#         )\n",
    "\n",
    "#         # Attention Layer\n",
    "#         self.attention_heads = MultiHeadDotAttention(node_dim = node_dim, num_heads = num_heads, device = device)\n",
    "\n",
    "#         # Normalization\n",
    "#         self.norm_attn = nn.Sequential(\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             Normalization(node_dim = node_dim, device = device),\n",
    "#         )\n",
    "\n",
    "#         # Node and edge MLPs\n",
    "#         self.mlp_nodes = nn.Sequential(\n",
    "#             nn.Linear(in_features = node_dim, out_features = node_dim, device = device),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             nn.Linear(in_features = node_dim, out_features = node_dim, device = device),\n",
    "#             # nn.LeakyReLU(0.1),\n",
    "#         )\n",
    "\n",
    "#         # # Conditioning\n",
    "#         # self.film_in = FiLM(node_dim = node_dim, cond_dim = cond_dim, device = device)\n",
    "#         # self.film_attn = FiLM(node_dim = node_dim, cond_dim = cond_dim, device = device)\n",
    "#         # self.mul = nn.Linear(in_features = cond_dim, out_features = 2 * (node_dim + edge_dim), device = device)\n",
    "#         self.lin_cond = nn.Linear(in_features = cond_dim, out_features = 4 * node_dim, device = device)\n",
    "\n",
    "#     def forward(self, nodes : Tensor, conds : Tensor) -> Tensor:\n",
    "#         mul_in, add_in, mul_attn, add_attn = self.lin_cond(conds.unsqueeze(1)).chunk(chunks = 4, dim = -1)\n",
    "#         # Attention\n",
    "#         nodes = self.attention_heads(nodes) + nodes\n",
    "#         nodes = self.norm_in(nodes) * mul_in + add_in\n",
    "#         # MLP\n",
    "#         nodes = self.mlp_nodes(nodes) + nodes\n",
    "#         nodes = self.norm_attn(nodes) * mul_attn + add_attn\n",
    "\n",
    "#         # # Attention\n",
    "#         # nodes = self.attention_heads(self.film_in(self.norm_in(nodes), conds)) + nodes\n",
    "#         # # MLP\n",
    "#         # nodes = self.mlp_nodes(self.film_attn(self.norm_attn(nodes), conds)) + nodes\n",
    "\n",
    "#         return nodes\n",
    "\n",
    "# class MultiHeadMLPAttention(nn.Module):\n",
    "#     def __init__(self, node_dim : int, num_heads : int, device : torch.device):\n",
    "#         super().__init__()\n",
    "#         self.num_heads = num_heads\n",
    "#         self.attn_dim = 32\n",
    "\n",
    "#         self.lin_vw = nn.Sequential(\n",
    "#             nn.Linear(in_features = 2 * node_dim, out_features = 2 * node_dim, device = device),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             nn.Linear(in_features = 2 * node_dim, out_features = num_heads * self.attn_dim + num_heads, device = device)\n",
    "#         )\n",
    "\n",
    "#         self.lin_nodes_out = nn.Linear(in_features = num_heads * self.attn_dim, out_features = node_dim, device = device)                \n",
    "\n",
    "#     def forward(self, nodes : Tensor) -> Tensor:\n",
    "#         b, n, d = nodes.size()\n",
    "#         h = self.num_heads\n",
    "        \n",
    "#         features = torch.cat([nodes.unsqueeze(1).expand(-1, n, -1, -1), nodes.unsqueeze(2).expand(-1, -1, n, -1)], dim = -1)\n",
    "#         v, w = self.lin_vw(features).split([self.num_heads * self.attn_dim, self.num_heads], dim = -1)\n",
    "#         v = v.reshape(b, n, n, h, -1)\n",
    "#         w = w.reshape(b, n, n, h, -1).softmax(dim = 2)\n",
    "#         # w = (w * w / w.size(-1)).sum(dim = -1, keepdim = True).softmax(dim = 2)\n",
    "#         weighted_values = (w * v).sum(dim = 2).flatten(start_dim = 2)\n",
    "\n",
    "#         return self.lin_nodes_out(weighted_values)\n",
    "    \n",
    "# class MultiHeadDotAttention(nn.Module):\n",
    "#     def __init__(self, node_dim : int, num_heads : int, device : torch.device):\n",
    "#         super().__init__()\n",
    "#         self.node_dim = node_dim\n",
    "#         self.num_heads = num_heads\n",
    "#         attn_dim = 32\n",
    "\n",
    "#         self.lin_qkv = nn.Linear(in_features = self.node_dim, out_features = 3 * attn_dim * num_heads, device = device)\n",
    "\n",
    "#         self.lin_nodes_out = nn.Linear(in_features = attn_dim * num_heads, out_features = self.node_dim, device = device)                     \n",
    "\n",
    "#     def forward(self, nodes : Tensor) -> Tensor:\n",
    "#         batch_size, num_nodes, _ = nodes.size()\n",
    "        \n",
    "#         queries, keys, values = self.lin_qkv(nodes).chunk(chunks = 3, dim = -1)\n",
    "\n",
    "#         queries = queries.reshape(batch_size, num_nodes, self.num_heads, -1).permute(0, 2, 1, 3) # batch_size x num_heads x num_nodes x attn_dim\n",
    "#         keys = keys.reshape(batch_size, num_nodes, self.num_heads, -1).permute(0, 2, 1, 3)       # batch_size x num_heads x num_nodes x attn_dim\n",
    "#         values = values.reshape(batch_size, num_nodes, self.num_heads, -1).permute(0, 2, 1, 3)   # batch_size x num_heads x num_nodes x attn_dim\n",
    "\n",
    "#         weighted_values = F.scaled_dot_product_attention(query = queries, key = keys, value = values, scale = 1).permute(0, 2, 1, 3).flatten(start_dim = 2)\n",
    "\n",
    "#         return self.lin_nodes_out(weighted_values)\n",
    "\n",
    "# class Normalization(nn.Module):\n",
    "#     def __init__(self, node_dim: int, device: device):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.norm_nodes = nn.InstanceNorm1d(num_features = node_dim, device = device)\n",
    "#         # self.norm_nodes = nn.BatchNorm1d(num_features = node_dim, affine = False, device = device)\n",
    "#         # self.norm_nodes = nn.LayerNorm(normalized_shape = node_dim, elementwise_affine = False, device = device)\n",
    "\n",
    "#     def forward(self, nodes : Tensor) -> Tensor:\n",
    "#         return self.norm_nodes(nodes.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "#         # return self.norm_nodes(nodes)\n",
    "\n",
    "# class FiLM(nn.Module):\n",
    "#     def __init__(self, node_dim : int, cond_dim : int, device : device):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.lin_node = nn.Linear(in_features = cond_dim, out_features = 2 * node_dim, device = device)\n",
    "    \n",
    "#     def forward(self, node : Tensor, cond : Tensor) -> Tensor:\n",
    "#         node_mul, node_add = self.lin_node(cond).unsqueeze(1).chunk(chunks = 2, dim = -1)\n",
    "\n",
    "#         return node_mul * node + node_add + node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossDiffusionModel(nn.Module):\n",
    "    def __init__(self, node_dim, node_hidden_dim, cond_hidden_dim, num_heads, num_tf_layers, num_checkpoints, max_timestep, device: device):\n",
    "        super().__init__()\n",
    "        self.num_checkpoints = num_checkpoints\n",
    "\n",
    "        self.time_embedder = TimeEmbedder(max_timestep, cond_hidden_dim, device)\n",
    "        self.pos_embedder = SinuisodalEncoding(max_length = 24, embedding_dimension = node_hidden_dim, device = device)\n",
    "\n",
    "        # Input MLP layers\n",
    "        self.mlp_in_nodes = nn.Sequential(\n",
    "            nn.Linear(in_features = node_dim, out_features = node_hidden_dim, device = device),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(in_features = node_hidden_dim, out_features = 2 * node_hidden_dim, device = device),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        )\n",
    "\n",
    "        self.mlp_in_conds = nn.Sequential(\n",
    "            nn.Linear(in_features = cond_hidden_dim, out_features = cond_hidden_dim, device = device),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(in_features = cond_hidden_dim, out_features = cond_hidden_dim, device = device),\n",
    "            nn.LeakyReLU(0.1)\n",
    "        )\n",
    "\n",
    "        # Transformer Layers with Graph Attention Network\n",
    "        self.block_layers = nn.ModuleList([\n",
    "            TransformerLayer(\n",
    "                node_dim = node_hidden_dim,\n",
    "                cond_dim = cond_hidden_dim,\n",
    "                num_heads = num_heads,\n",
    "                device = device\n",
    "            ) for _ in range(num_tf_layers)\n",
    "        ])\n",
    "        \n",
    "        # Output MLP layers\n",
    "        self.mlp_out_params = nn.Sequential(\n",
    "            nn.Linear(in_features = node_hidden_dim, out_features = node_hidden_dim, device = device),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(in_features = node_hidden_dim, out_features = 7, device = device)\n",
    "        )\n",
    "        self.mlp_out_types = nn.Sequential(\n",
    "            nn.Linear(in_features = node_hidden_dim, out_features = node_hidden_dim, device = device),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(in_features = node_hidden_dim, out_features = 14, device = device)\n",
    "        )\n",
    "\n",
    "    def forward(self, nodes : Tensor, timestep : Tensor):\n",
    "        params, types = self.mlp_in_nodes(nodes).chunk(chunks = 2, dim = -1)     # shape: (batch_size, num_nodes, node_hidden_dim)\n",
    "        # params = params + self.pos_embedder.embs\n",
    "        # types = types + self.pos_embedder.embs\n",
    "        conds = self.time_embedder(timestep) # shape: (batch_size, cond_hidden_dim)\n",
    "        conds = self.mlp_in_conds(conds)     # shape: (batch_size, cond_hidden_dim)\n",
    "\n",
    "        # nodes = nodes + conds.unsqueeze(1)\n",
    "        # edges = edges + conds.unsqueeze(1).unsqueeze(1)\n",
    "        checkpoints = self.num_checkpoints\n",
    "        for layer in self.block_layers:\n",
    "            params, types = layer(params, types, conds) # shape: (batch_size, num_nodes, node_hidden_dim) ; shape: (batch_size, num_nodes, num_nodes, edge_hidden_dim)\n",
    "            checkpoints = checkpoints - 1\n",
    "\n",
    "        nodes = torch.cat([self.mlp_out_types(types), self.mlp_out_params(params)], dim = -1) # shape: (batch_size, num_nodes, node_dim)\n",
    "\n",
    "        return nodes\n",
    "\n",
    "class TransformerLayer(nn.Module):\n",
    "    def __init__(self, node_dim: int, cond_dim: int, num_heads: int, device: device):\n",
    "        super().__init__()\n",
    "        self.node_dim = node_dim\n",
    "\n",
    "        # Normalization\n",
    "        self.norm_in = Normalization(node_dim = node_dim, device = device)\n",
    "\n",
    "        # Attention Layer\n",
    "        self.attention_heads = MultiHeadCrossAttention(node_dim = node_dim, num_heads = num_heads, device = device)\n",
    "\n",
    "        # Normalization\n",
    "        self.norm_attn = Normalization(node_dim = node_dim, device = device)\n",
    "\n",
    "        # Node and edge MLPs\n",
    "        self.mlp_params = nn.Sequential(\n",
    "            nn.Linear(in_features = node_dim, out_features = node_dim, device = device),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(in_features = node_dim, out_features = node_dim, device = device),\n",
    "            # nn.LeakyReLU(0.1),\n",
    "        )\n",
    "        self.mlp_types = nn.Sequential(\n",
    "            nn.Linear(in_features = node_dim, out_features = node_dim, device = device),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(in_features = node_dim, out_features = node_dim, device = device),\n",
    "            # nn.LeakyReLU(0.1),\n",
    "        )\n",
    "\n",
    "        # Conditioning\n",
    "        self.lin_cond = nn.Linear(in_features = cond_dim, out_features = 8 * node_dim, device = device)\n",
    "\n",
    "    def forward(self, params : Tensor, types : Tensor, conds : Tensor) -> Tensor:\n",
    "        mul_inp, add_inp, mul_attnp, add_attnp, mul_int, add_int, mul_attnt, add_attnt = self.lin_cond(conds.unsqueeze(1)).chunk(chunks = 8, dim = -1)\n",
    "        # Attention\n",
    "        attn_params, attn_types = self.attention_heads(params, types)\n",
    "        params, types = self.norm_in(attn_params + params, attn_types + types)\n",
    "        params = params * mul_inp + add_inp + params\n",
    "        types = types * mul_int + add_int + types\n",
    "        # MLP\n",
    "        mlp_params, mlp_types = self.mlp_params(params), self.mlp_types(types)\n",
    "        params, types = self.norm_in(mlp_params + params, mlp_types + types)\n",
    "        params = params * mul_attnp + add_attnp + params\n",
    "        types = types * mul_attnt + add_attnt + types\n",
    "\n",
    "        return params, types\n",
    "\n",
    "class MultiHeadCrossAttention(nn.Module):\n",
    "    def __init__(self, node_dim : int, num_heads : int, device : torch.device):\n",
    "        super().__init__()\n",
    "        self.node_dim = node_dim\n",
    "        self.num_heads = num_heads\n",
    "        attn_dim = 32\n",
    "\n",
    "        self.lin_qkv_param = nn.Linear(in_features = self.node_dim, out_features = 3 * attn_dim * num_heads, device = device)\n",
    "        self.lin_qkv_type = nn.Linear(in_features = self.node_dim, out_features = 3 * attn_dim * num_heads, device = device)\n",
    "\n",
    "        self.lin_params_out = nn.Linear(in_features = attn_dim * num_heads, out_features = self.node_dim, device = device)\n",
    "        self.lin_types_out = nn.Linear(in_features = attn_dim * num_heads, out_features = self.node_dim, device = device)                    \n",
    "\n",
    "    def forward(self, params : Tensor, types : Tensor) -> Tensor:\n",
    "        batch_size, num_nodes, _ = params.size()\n",
    "        \n",
    "        queriesp, keysp, valuesp = self.lin_qkv_param(params).chunk(chunks = 3, dim = -1)\n",
    "        queriest, keyst, valuest = self.lin_qkv_type(types).chunk(chunks = 3, dim = -1)\n",
    "\n",
    "        queriesp = queriesp.reshape(batch_size, num_nodes, self.num_heads, -1).permute(0, 2, 1, 3) # batch_size x num_heads x num_nodes x attn_dim\n",
    "        keysp = keysp.reshape(batch_size, num_nodes, self.num_heads, -1).permute(0, 2, 1, 3)       # batch_size x num_heads x num_nodes x attn_dim\n",
    "        valuesp = valuesp.reshape(batch_size, num_nodes, self.num_heads, -1).permute(0, 2, 1, 3)   # batch_size x num_heads x num_nodes x attn_dim\n",
    "        queriest = queriest.reshape(batch_size, num_nodes, self.num_heads, -1).permute(0, 2, 1, 3) # batch_size x num_heads x num_nodes x attn_dim\n",
    "        keyst = keyst.reshape(batch_size, num_nodes, self.num_heads, -1).permute(0, 2, 1, 3)       # batch_size x num_heads x num_nodes x attn_dim\n",
    "        valuest = valuest.reshape(batch_size, num_nodes, self.num_heads, -1).permute(0, 2, 1, 3)   # batch_size x num_heads x num_nodes x attn_dim\n",
    "\n",
    "        weighted_params = F.scaled_dot_product_attention(query = queriest, key = keyst, value = valuesp, scale = 1).permute(0, 2, 1, 3).flatten(start_dim = 2)\n",
    "        weighted_types = F.scaled_dot_product_attention(query = queriesp, key = keysp, value = valuest, scale = 1).permute(0, 2, 1, 3).flatten(start_dim = 2)\n",
    "\n",
    "        return self.lin_params_out(weighted_params), self.lin_types_out(weighted_types)\n",
    "\n",
    "class Normalization(nn.Module):\n",
    "    def __init__(self, node_dim: int, device: device):\n",
    "        super().__init__()\n",
    "        \n",
    "        # self.norm_nodes = nn.InstanceNorm1d(num_features = node_dim, device = device)\n",
    "        # self.norm_nodes = nn.BatchNorm1d(num_features = node_dim, affine = False, device = device)\n",
    "        self.norm_params = nn.InstanceNorm1d(num_features = node_dim, device = device)\n",
    "        self.norm_types = nn.InstanceNorm1d(num_features = node_dim, device = device)\n",
    "\n",
    "    def forward(self, params : Tensor, types : Tensor) -> Tensor:\n",
    "        # return self.norm_nodes(nodes.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        return self.norm_params(params.permute(0, 2, 1)).permute(0, 2, 1), self.norm_types(types.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "\n",
    "class FiLM(nn.Module):\n",
    "    def __init__(self, node_dim : int, cond_dim : int, device : device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lin_node = nn.Linear(in_features = cond_dim, out_features = 2 * node_dim, device = device)\n",
    "    \n",
    "    def forward(self, node : Tensor, cond : Tensor) -> Tensor:\n",
    "        node_mul, node_add = self.lin_node(cond).unsqueeze(1).chunk(chunks = 2, dim = -1)\n",
    "\n",
    "        return node_mul * node + node_add + node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GD3PM(nn.Module):\n",
    "  def __init__(self, device : torch.device):\n",
    "    super().__init__()\n",
    "    self.device = device\n",
    "    self.node_dim = NODE_FEATURE_DIMENSION + 1\n",
    "    self.node_hidden_dim = 256\n",
    "    self.cond_hidden_dim = 256\n",
    "    self.num_tf_layers = 16\n",
    "    self.num_checkpoints = 0\n",
    "    self.num_heads = 8\n",
    "    self.max_timestep = 1000\n",
    "    self.noise_scheduler = CosineNoiseScheduler(self.max_timestep, self.device)\n",
    "    self.architecture = CrossDiffusionModel(node_dim = self.node_dim, \n",
    "                                  node_hidden_dim = self.node_hidden_dim,\n",
    "                                  cond_hidden_dim = self.cond_hidden_dim,\n",
    "                                  num_heads = self.num_heads,\n",
    "                                  num_tf_layers = self.num_tf_layers,\n",
    "                                  num_checkpoints = self.num_checkpoints,\n",
    "                                  max_timestep = self.max_timestep,\n",
    "                                  device = self.device)\n",
    "    # self.fine_model = CrossDiffusionModel(node_dim = self.node_dim, \n",
    "    #                                    node_hidden_dim = self.node_hidden_dim,\n",
    "    #                                    cond_hidden_dim = self.cond_hidden_dim,\n",
    "    #                                    num_heads = self.num_heads,\n",
    "    #                                    num_tf_layers = self.num_tf_layers,\n",
    "    #                                    num_checkpoints = self.num_checkpoints,\n",
    "    #                                    max_timestep = self.max_timestep,\n",
    "    #                                    device = self.device)\n",
    "    # self.coarse_model = CrossDiffusionModel(node_dim = self.node_dim, \n",
    "    #                                    node_hidden_dim = self.node_hidden_dim,\n",
    "    #                                    cond_hidden_dim = self.cond_hidden_dim,\n",
    "    #                                    num_heads = self.num_heads,\n",
    "    #                                    num_tf_layers = self.num_tf_layers,\n",
    "    #                                    num_checkpoints = self.num_checkpoints,\n",
    "    #                                    max_timestep = self.max_timestep,\n",
    "    #                                    device = self.device)\n",
    "    # self.step_cutoff = self.max_timestep // 2\n",
    "\n",
    "  def forward(self, nodes : Tensor, timestep : Tensor):\n",
    "    # # Output Buffer\n",
    "    # out_nodes = torch.zeros_like(nodes)\n",
    "\n",
    "    # # Split small perturbations from large perturbations\n",
    "    # s_idx = torch.nonzero(timestep < self.step_cutoff).squeeze(-1)\n",
    "    # l_idx = torch.nonzero(timestep >= self.step_cutoff).squeeze(-1)\n",
    "\n",
    "    # # Fine model refines small perturbations\n",
    "    # if s_idx.nelement() != 0: out_nodes[s_idx] = self.fine_model(nodes[s_idx], timestep[s_idx])\n",
    "    # # Coarse model refines large perturbations\n",
    "    # if l_idx.nelement() != 0: out_nodes[l_idx] = self.coarse_model(nodes[l_idx], timestep[l_idx])\n",
    "\n",
    "    # return out_nodes\n",
    "\n",
    "    # nodes = self.architecture(nodes, self.noise_scheduler.sqrt_b_bar[timestep])\n",
    "    # Normalize to Probabilities\n",
    "    # nodes[...,0:2] = nodes[...,0:2].softmax(dim = -1)\n",
    "    # nodes[...,2:7] = nodes[...,2:7].softmax(dim = -1)\n",
    "\n",
    "    nodes = self.architecture(nodes, timestep)\n",
    "    return nodes\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def sample(self, batch_size : int):\n",
    "    # Sample Noise\n",
    "    nodes = self.noise_scheduler.sample_latent(batch_size)\n",
    "    nodes = nodes.to(self.device)\n",
    "    return self.denoise(nodes)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def denoise(self, nodes, axes = None):\n",
    "    num_images = 10\n",
    "    j = num_images - 1\n",
    "    if axes is None:\n",
    "      fig, axes = plt.subplots(nrows = 1, ncols = num_images, figsize=(40, 4))\n",
    "    stepsize = int(self.max_timestep/num_images)\n",
    "    \n",
    "    for t in reversed(range(1, self.max_timestep)):\n",
    "      # model expects a timestep for each batch\n",
    "      batch_size = nodes.size(0)\n",
    "      time = torch.Tensor([t]).expand(batch_size).int().to(self.device)\n",
    "      nodes = self.reverse(self.forward(nodes, time), nodes, t)\n",
    "\n",
    "      if t % stepsize == 0:\n",
    "        SketchDataset.render_graph(nodes[0,...,1:].cpu(), torch.zeros(size = (24, 24, 17)).cpu(), axes[j])\n",
    "        j = j - 1\n",
    "    \n",
    "    SketchDataset.render_graph(nodes[0,...,1:].cpu(), torch.zeros(size = (24, 24, 17)).cpu(), axes[0])\n",
    "    # plt.show(fig)\n",
    "    # plt.close(fig)\n",
    "\n",
    "    return nodes\n",
    "  \n",
    "  @torch.no_grad()\n",
    "  def reverse(self, pred_nodes, curr_nodes, timestep):\n",
    "    denoised_nodes = torch.zeros_like(pred_nodes)\n",
    "    denoised_nodes[...,0:2] = self.noise_scheduler.discrete_posterior_step(pred_nodes[...,0:2].softmax(dim = -1), curr_nodes[...,0:2], timestep)\n",
    "    denoised_nodes[...,2:7] = self.noise_scheduler.discrete_posterior_step(pred_nodes[...,2:7].softmax(dim = -1), curr_nodes[...,2:7], timestep)\n",
    "    denoised_nodes[...,7:] = self.noise_scheduler.continuous_posterior_step(pred_nodes[...,7:], curr_nodes[...,7:], timestep)\n",
    "    return denoised_nodes\n",
    "    # nodes, _ = self.noise_scheduler(pred_nodes, timestep - 1)\n",
    "    # return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitGD3PM(nn.Module):\n",
    "  def __init__(self, device : torch.device):\n",
    "    super().__init__()\n",
    "    self.device = device\n",
    "    self.node_dim = NODE_FEATURE_DIMENSION\n",
    "    self.node_hidden_dim = 512\n",
    "    self.cond_hidden_dim = 512\n",
    "    self.num_tf_layers = 32\n",
    "    self.num_checkpoints = 0\n",
    "    self.num_heads = 16\n",
    "    self.max_timestep = 1000\n",
    "    self.noise_scheduler = CosineNoiseScheduler(self.max_timestep, self.device)\n",
    "    self.step_cutoff = self.max_timestep // 2\n",
    "    self.fine_model = CrossDiffusionModel(node_dim = self.node_dim, \n",
    "                                       node_hidden_dim = self.node_hidden_dim,\n",
    "                                       cond_hidden_dim = self.cond_hidden_dim,\n",
    "                                       num_heads = self.num_heads,\n",
    "                                       num_tf_layers = self.num_tf_layers,\n",
    "                                       num_checkpoints = self.num_checkpoints // 2,\n",
    "                                       max_timestep = self.max_timestep,\n",
    "                                       device = self.device)\n",
    "    self.coarse_model = CrossDiffusionModel(node_dim = self.node_dim, \n",
    "                                       node_hidden_dim = self.node_hidden_dim,\n",
    "                                       cond_hidden_dim = self.cond_hidden_dim,\n",
    "                                       num_heads = self.num_heads,\n",
    "                                       num_tf_layers = self.num_tf_layers,\n",
    "                                       num_checkpoints = self.num_checkpoints // 2,\n",
    "                                       max_timestep = self.max_timestep,\n",
    "                                       device = self.device)\n",
    "\n",
    "  def forward(self, nodes : Tensor, timestep : Tensor):\n",
    "    # Output Buffer\n",
    "    out_nodes = torch.zeros_like(nodes)\n",
    "\n",
    "    # Split small perturbations from large perturbations\n",
    "    s_idx = torch.nonzero(timestep < self.step_cutoff).squeeze(-1)\n",
    "    l_idx = torch.nonzero(timestep >= self.step_cutoff).squeeze(-1)\n",
    "\n",
    "    # Fine model refines small perturbations\n",
    "    if s_idx.nelement() != 0: out_nodes[s_idx] = self.fine_model(nodes[s_idx], timestep[s_idx])\n",
    "    # Coarse model refines large perturbations\n",
    "    if l_idx.nelement() != 0: out_nodes[l_idx] = self.coarse_model(nodes[l_idx], timestep[l_idx])\n",
    "    \n",
    "    # nodes = self.architecture(nodes, timestep)\n",
    "    # Normalize to Probabilities\n",
    "    s = (1 - self.noise_scheduler.sqrt_b_bar[timestep, None]) ** 0.5\n",
    "    out_nodes[...,0] = (out_nodes[...,0] / s).sigmoid()\n",
    "    out_nodes[...,1:6] = (out_nodes[...,1:6] / s.unsqueeze(-1)).softmax(dim = -1)\n",
    "\n",
    "    return out_nodes\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def sample(self, batch_size : int):\n",
    "    # Sample Noise\n",
    "    nodes = self.noise_scheduler.sample_latent(batch_size)\n",
    "    nodes = nodes.to(self.device)\n",
    "    return self.denoise(nodes)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def denoise(self, nodes, axes = None):\n",
    "    num_images = 10\n",
    "    j = num_images - 1\n",
    "    if axes is None:\n",
    "      fig, axes = plt.subplots(nrows = 1, ncols = num_images, figsize=(40, 4))\n",
    "    stepsize = int(self.max_timestep/num_images)\n",
    "    \n",
    "    for t in reversed(range(1, self.max_timestep)):\n",
    "      # model expects a timestep for each batch\n",
    "      batch_size = nodes.size(0)\n",
    "      time = torch.Tensor([t]).expand(batch_size).int().to(self.device)\n",
    "      nodes, _ = self.noise_scheduler(self.forward(nodes, time), t - 1)\n",
    "\n",
    "      if t % stepsize == 1:\n",
    "        SketchDataset.render_graph(nodes[0].cpu(), torch.zeros(size = (24, 24, 17)).cpu(), axes[j])\n",
    "        j = j - 1\n",
    "      \n",
    "    # plt.show(fig)\n",
    "    # plt.close(fig)\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffusion_loss(pred_nodes : Tensor, true_nodes : Tensor, params_mask : Tensor, loss_dict : dict, scales : Tensor) -> Tensor:\n",
    "    primitive_type_labels = torch.argmax(true_nodes[:,:,2:7], dim = 2)    # batch_size x num_nodes (class index for each node)\n",
    "    primitive_type_logits = pred_nodes[:,:,2:7]#.permute(0,2,1).contiguous() # batch_size x num_primitive_types x num_nodes\n",
    "    \n",
    "    node_cross = F.cross_entropy(\n",
    "        input = primitive_type_logits.reshape(-1, 5), \n",
    "        target = primitive_type_labels.flatten(),\n",
    "        # weight = weight, \n",
    "        reduction = 'mean')\n",
    "    \n",
    "    construct_type_labels = torch.argmax(true_nodes[:,:,0:2], dim = 2)    # batch_size x num_nodes (class index for each node)\n",
    "    construct_type_logits = pred_nodes[:,:,0:2]#.permute(0,2,1).contiguous() # batch_size x num_primitive_types x num_nodes\n",
    "    \n",
    "    bce = F.cross_entropy(\n",
    "        input = construct_type_logits.reshape(-1, 2), \n",
    "        target = construct_type_labels.flatten(),\n",
    "        # weight = weight, \n",
    "        reduction = 'mean')\n",
    "\n",
    "    # pred_noise = pred_nodes[:,:,6:]\n",
    "    # mse = ((pred_noise - true_noise) ** 2 * params_mask).sum() / params_mask.sum() * node_mse_weight \n",
    "    pred_params = pred_nodes[:,:,7:]\n",
    "    target_params = true_nodes[:,:,7:]\n",
    "    mse = ((pred_params - target_params) ** 2 * params_mask).sum() / params_mask.sum()\n",
    "\n",
    "    node_loss = bce + node_cross + mse\n",
    "\n",
    "    loss_dict[\"node loss\"] = bce.item() + node_cross.item() + mse.item()\n",
    "    loss_dict[\"node construct\"] = bce.item()\n",
    "    loss_dict[\"node type\"] = node_cross.item()\n",
    "    loss_dict[\"node param\"] = mse.item()\n",
    "\n",
    "    return node_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(writer : SummaryWriter, loss_dict : dict, step : int):\n",
    "    writer.add_scalar(\"Training/Node_Loss\",      loss_dict[\"node loss\"],      step)\n",
    "    writer.add_scalar(\"Training/Node_Construct\", loss_dict[\"node construct\"], step)\n",
    "    writer.add_scalar(\"Training/Node_Type\",      loss_dict[\"node type\"],      step)\n",
    "    writer.add_scalar(\"Training/Node_Param\",     loss_dict[\"node param\"],     step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50000\n",
    "lr = 1e-4\n",
    "batch_size = 256\n",
    "experiment_string = f\"nodediffusion_Adam_overfit_test1\"\n",
    "writer = SummaryWriter(f'runs6/{experiment_string}')\n",
    "gpu_id = 0\n",
    "\n",
    "# tensor_dict = torch.load('temp_dataset.pth')\n",
    "\n",
    "# nodes = tensor_dict[\"nodes\"].to(gpu_id)\n",
    "# # nodes = ToIscosceles(nodes)\n",
    "\n",
    "# # edges = tensor_dict[\"edges\"].to(gpu_id)\n",
    "# params_mask = tensor_dict[\"params_mask\"].to(gpu_id)\n",
    "\n",
    "nodes = torch.load(\"data/processed/nodes1.pt\")\n",
    "nodes = torch.cat([1 - nodes[...,0].unsqueeze(-1), nodes], dim = -1)\n",
    "params_mask = torch.load(\"data/processed/node_params_mask.pt\")\n",
    "\n",
    "dataset = TensorDataset(nodes, params_mask)\n",
    "# train_loader = DataLoader(dataset = dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "train_set, _ = random_split(dataset = dataset, lengths = [0.05, 0.95], generator = torch.Generator().manual_seed(4))\n",
    "train_loader = DataLoader(dataset = train_set, batch_size = batch_size, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GD3PM(gpu_id)\n",
    "\n",
    "# my_list = ['time', 'cond']\n",
    "\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = lr)\n",
    "# cond_params = [param for name, param in model.named_parameters() if any(substring in name for substring in my_list)]\n",
    "# base_params = [param for name, param in model.named_parameters() if not any(substring in name for substring in my_list)]\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params': base_params},\n",
    "#     {'params': cond_params, 'lr': 1e-8}\n",
    "#     ], lr = lr)\n",
    "# scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lambda epoch: 1 / max(epoch / 10_000, 1) ** 0.5)\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/416 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 416/416 [01:19<00:00,  5.20it/s]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "global_step = 0\n",
    "for epoch in range(num_epochs):\n",
    "    # print(f\"---Training Epoch {epoch}---\")\n",
    "    model.train()\n",
    "    for nodes, params_mask in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        nodes = nodes.to(gpu_id)\n",
    "        params_mask = params_mask.to(gpu_id)\n",
    "\n",
    "        t = torch.randint(low = 1, high = model.max_timestep, size = (nodes.size(0),)).to(gpu_id)\n",
    "        # t = torch.rand(size = (nodes.size(0),), device = gpu_id)\n",
    "        # alpha = 0.5\n",
    "        # beta = model.step_cutoff / model.max_timestep\n",
    "        # t = torch.where(t < alpha, beta * t / alpha, beta + (1 - beta) * (t - alpha) / (1 - alpha)) * model.max_timestep\n",
    "        # t = t.int()  \n",
    "        noised_nodes, added_noise = model.noise_scheduler(nodes, t)\n",
    "\n",
    "        pred_nodes = model(noised_nodes, t)\n",
    "\n",
    "        loss_dict = {}\n",
    "        # scales = torch.where(t < 100, 9, 1)\n",
    "        scales = 1 # scales.unsqueeze(1).unsqueeze(1)\n",
    "        loss = diffusion_loss(pred_nodes, nodes, params_mask, loss_dict, scales)\n",
    "\n",
    "        plot_loss(writer, loss_dict, global_step)\n",
    "        # pbar.set_description(f\"Iter Loss: {loss.item()}\")\n",
    "\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        global_step = global_step + 1\n",
    "        # scheduler.step()\n",
    "        # writer.add_scalar(\"LR\", scheduler.get_last_lr()[0], step)\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        model.eval()\n",
    "        fig, axes = plt.subplots(nrows = 1, ncols = 10, figsize=(40, 4))\n",
    "        seed = model.noise_scheduler.sample_latent(1)\n",
    "        sample = model.denoise(seed, axes)\n",
    "        writer.add_figure(\"Visualization\", fig, epoch)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     temp_nodes = model.sample(20)\n",
    "\n",
    "#     for i in range(temp_nodes.size(0)):\n",
    "#         SketchDataset.render_graph(temp_nodes[i].cpu(), torch.zeros(size = (24, 24, 17)).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = gpu_id\n",
    "# max_timestep = 1000\n",
    "# noise_scheduler = CosineNoiseScheduler(max_timestep, device = gpu_id)\n",
    "# num_images = 10\n",
    "# j = num_images - 1\n",
    "# fig, axes = plt.subplots(nrows = 1, ncols = num_images, figsize=(40, 4))\n",
    "# stepsize = int(max_timestep/num_images)\n",
    "\n",
    "# true = nodes[None,0].to(gpu_id)\n",
    "\n",
    "# latent = noise_scheduler.sample_latent(1)\n",
    "    \n",
    "# for t in reversed(range(0, max_timestep)):\n",
    "#     # model expects a timestep for each batch\n",
    "#     latent[...,0:2] = noise_scheduler.discrete_posterior_step(true[...,0:2], latent[...,0:2], t)\n",
    "#     latent[...,2:7] = noise_scheduler.discrete_posterior_step(true[...,2:7], latent[...,2:7], t)\n",
    "#     latent[...,7:] = noise_scheduler.continuous_posterior_step(true[...,7:], latent[...,7:], t)\n",
    "\n",
    "#     assert latent.isfinite().all(), t\n",
    "\n",
    "#     if t % stepsize == 0:\n",
    "#         SketchDataset.render_graph(latent[0,...,1:].cpu(), torch.zeros(size = (24, 24, 17)).cpu(), axes[j])\n",
    "#         j = j - 1\n",
    "      \n",
    "# plt.show(fig)\n",
    "# plt.close(fig)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
