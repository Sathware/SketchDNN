{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import multiprocessing\n",
    "import math\n",
    "from torch_geometric.data import Dataset, download_url, Data\n",
    "import torch_geometric.utils as pygutils\n",
    "from config import NODE_FEATURE_DIMENSION, EDGE_FEATURE_DIMENSION, MAX_NUM_PRIMITIVES, MAX_NUM_CONSTRAINTS, NUM_PRIMITIVE_TYPES\n",
    "# You have to import sketchgraphs this way otherwise you get type errors\n",
    "os.chdir('SketchGraphs/')\n",
    "import sketchgraphs.data as datalib\n",
    "from sketchgraphs.data import flat_array\n",
    "from sketchgraphs.data._entity import Point, Line, Circle, Arc, EntityType\n",
    "from sketchgraphs.data.sketch import Sketch\n",
    "from sketchgraphs.data._constraint import *\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data : Data):\n",
    "    # Pad node feature matrix to have maximum 24 nodes\n",
    "    x = data.nodes.to_dense()\n",
    "    nodes = torch.zeros(size = (MAX_NUM_PRIMITIVES, NODE_FEATURE_DIMENSION))\n",
    "    num_primitives = len(x)\n",
    "    nodes[:num_primitives] = x\n",
    "    nodes[num_primitives:] = torch.tensor([0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "    # Convert sparse edge feature tensor to dense tensor\n",
    "    edges = data.edges.to_dense()\n",
    "    edges[torch.abs(edges).sum(dim = 2) == 0] = torch.Tensor([0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1])\n",
    "    # Convert sparse node parameter mask to dense tensor\n",
    "    node_params_mask = data.node_params_mask.to_dense()\n",
    "    return nodes, edges, node_params_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SketchDataset(Dataset):\n",
    "    def __init__(self, root, transform = transform, pre_transform = None, pre_filter = None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['sg_all.npy']\n",
    "    \n",
    "    @property \n",
    "    def processed_file_names(self):\n",
    "        # Make processed dir if not already exist\n",
    "        if os.path.exists(self.processed_dir):\n",
    "            return [\"finished_processing\"] # Check if the file 'finished_processing' is present in processed dir\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    @property\n",
    "    def num_node_features(self):\n",
    "        return 20\n",
    "    \n",
    "    @property\n",
    "    def num_edge_features(self):\n",
    "        return 17\n",
    "    \n",
    "    def download(self):\n",
    "        path = download_url(url = \"https://sketchgraphs.cs.princeton.edu/sequence/sg_all.npy\", \n",
    "                            folder = self.raw_dir\n",
    "                           );\n",
    "        # print(\"Downloaded SketchGraphs dataset to \" + path)\n",
    "\n",
    "    def process(self):\n",
    "        # Change dir to SketchGraphs so module not found error doesn't popup\n",
    "        os.chdir('SketchGraphs/')\n",
    "        # Load SketchGraphs sequence data dictionary\n",
    "        seq_data = flat_array.load_dictionary_flat(os.path.join(\"../\", self.raw_paths[0]))\n",
    "        sequences = seq_data[\"sequences\"]\n",
    "        idx = 0\n",
    "        for i in tqdm(range(len(sequences))):\n",
    "            seq = sequences[i]\n",
    "            sketch = datalib.sketch_from_sequence(seq)\n",
    "            # Filter out sketches with less than 7 or more than 24 primitives\n",
    "            # or less constraints than primitives or more than 208 constraints\n",
    "            if len(sketch.entities) < 7 or len(sketch.entities) > 24 or len(sketch.constraints) < len(sketch.entities) or len(sketch.constraints) > 208:\n",
    "                continue\n",
    "            # Construct Data Object containing graph\n",
    "            node_features, adjacency_list, edge_features = SketchDataset.sketch_to_graph(sketch)\n",
    "            node_params_mask = SketchDataset.params_mask(node_features)\n",
    "            data = Data()\n",
    "            \n",
    "            # Normalize node paramter values (except arc startParam and endParam) to be in range [-10, 10]\n",
    "            val_indices = [6,7,8,9,10,11,12,13,14,15,18,19]\n",
    "            node_features[:,val_indices] = node_features[:,val_indices] * 10 / torch.max(torch.abs(node_features[:,val_indices]))\n",
    "            \n",
    "            if (node_features.isnan().any()):\n",
    "                continue\n",
    "                #raise ValueError(\"node_features contain a nan!\")\n",
    "            if (adjacency_list.isnan().any()):\n",
    "                continue\n",
    "                #raise ValueError(\"adjacency_list contain a nan!\")\n",
    "            if (edge_features.isnan().any()):\n",
    "                continue\n",
    "                #raise ValueError(\"edge_features contain a nan!\")\n",
    "            if (node_params_mask.isnan().any()):\n",
    "                continue\n",
    "                #raise ValueError(\"node_params_mask contain a nan!\")\n",
    "            \n",
    "            # data = Data(x = node_features.to_sparse(), edge_index = adjacency_list, edge_attr = edge_features)\n",
    "            # Add arguments to data\n",
    "            \n",
    "            data.nodes = node_features.to_sparse()\n",
    "            data.edges = torch.sparse_coo_tensor(adjacency_list, edge_features, (24, 24, 17))\n",
    "            data.node_params_mask = node_params_mask.to_sparse()\n",
    "            # For whatever reason there is a limit of ~3 million files/sub directories per directory on my university's nfs share, \n",
    "            # so ~4.4 million data files are partitioned into ~88 subdirectories containing atmost 50,000 data files each\n",
    "            os.makedirs( name = os.path.join(\"../\", self.processed_dir, f'{int(idx / 50000)}'), exist_ok = True )\n",
    "            torch.save(data, os.path.join(\"../\", self.processed_dir, f'{int(idx / 50000)}/data_{idx}.pt'))\n",
    "            idx += 1\n",
    "        # Save file flag and Change dir back\n",
    "        open(os.path.join(\"../\", self.processed_dir, 'finished_processing'), 'a').close()\n",
    "        os.chdir('../')\n",
    "        print(\"Saved Graphs: \", idx)\n",
    "        \n",
    "    @staticmethod\n",
    "    def sketch_to_graph(sketch):\n",
    "        # Setup output data structures\n",
    "        num_nodes = len(sketch.entities)\n",
    "        num_edges = len(sketch.constraints)\n",
    "        # Node feature matrix\n",
    "        node_matrix = torch.zeros(size=(num_nodes if num_nodes < MAX_NUM_PRIMITIVES else MAX_NUM_PRIMITIVES, NODE_FEATURE_DIMENSION));\n",
    "        # Adjacency matrix\n",
    "        edge_index = torch.zeros(size=(num_edges if num_edges < MAX_NUM_CONSTRAINTS else MAX_NUM_CONSTRAINTS, 2));\n",
    "        # Edge feature matrix\n",
    "        edge_attr = torch.zeros(size=(num_edges if num_edges < MAX_NUM_CONSTRAINTS else MAX_NUM_CONSTRAINTS, EDGE_FEATURE_DIMENSION));\n",
    "        # Build node feature matrix according to the schema outlined in paper\n",
    "        idx = 0;\n",
    "        node_ref_to_idx = {};\n",
    "        for key, value in sketch.entities.items():\n",
    "            # Enforce maximum 24 primitives limit\n",
    "            if (idx == MAX_NUM_PRIMITIVES):\n",
    "                break\n",
    "            \n",
    "            node_feature = torch.zeros(20);\n",
    "            node_ref_to_idx[key] = idx;\n",
    "            node_feature[0] = int(value.isConstruction);\n",
    "            match value.type:\n",
    "                case EntityType.Line:\n",
    "                    node_feature[1] = 1;\n",
    "                    node_feature[6:8] = torch.from_numpy(value.start_point);\n",
    "                    node_feature[8:10] = torch.from_numpy(value.end_point);\n",
    "                case EntityType.Circle:\n",
    "                    node_feature[2] = 1;\n",
    "                    node_feature[10:12] = torch.from_numpy(value.center_point);\n",
    "                    node_feature[12] = value.radius;\n",
    "                case EntityType.Arc:\n",
    "                    node_feature[3] = 1;\n",
    "                    node_feature[13:15] = torch.from_numpy(value.center_point);\n",
    "                    node_feature[15] = value.radius;\n",
    "                    angle_start_offset = value.endParam if value.clockwise else value.startParam;\n",
    "                    angle_end_offset = value.startParam if value.clockwise else value.endParam;\n",
    "                    angle = math.atan2(value.yDir, value.xDir);\n",
    "                    node_feature[16] = ((angle + angle_start_offset) % (2*math.pi)) / (2*math.pi)\n",
    "                    node_feature[17] = ((angle + angle_end_offset) % (2*math.pi)) / (2*math.pi)\n",
    "                case EntityType.Point:\n",
    "                    node_feature[4] = 1;\n",
    "                    node_feature[18] = value.x;\n",
    "                    node_feature[19] = value.y;\n",
    "                case _:\n",
    "                    continue\n",
    "                \n",
    "            node_matrix[idx] = node_feature\n",
    "            idx += 1\n",
    "        # Remove all unused entries before returning, since there are a variable number of relevant primitives per sketch\n",
    "        node_matrix = node_matrix[:idx]\n",
    "        # Build adjacency list and edge feature matrix\n",
    "        idx = 0;\n",
    "        edge_exists = {}\n",
    "        for value in sketch.constraints.values():\n",
    "            # Enforce maximum 288 constraints limit\n",
    "            if (idx == MAX_NUM_CONSTRAINTS):\n",
    "                break\n",
    "            edge_feature = torch.zeros(17);\n",
    "            # Set one hot encoding for constraint type\n",
    "            match value.type:\n",
    "                case ConstraintType.Coincident:\n",
    "                    edge_feature[8] = 1;\n",
    "                case ConstraintType.Horizontal:\n",
    "                    edge_feature[9] = 1;\n",
    "                case ConstraintType.Vertical:\n",
    "                    edge_feature[10] = 1;\n",
    "                case ConstraintType.Parallel:\n",
    "                    edge_feature[11] = 1;\n",
    "                case ConstraintType.Perpendicular:\n",
    "                    edge_feature[12] = 1;\n",
    "                case ConstraintType.Tangent:\n",
    "                    edge_feature[13] = 1;\n",
    "                case ConstraintType.Midpoint:\n",
    "                    edge_feature[14] = 1;\n",
    "                case ConstraintType.Equal:\n",
    "                    edge_feature[15] = 1;\n",
    "                case _:\n",
    "                    continue;\n",
    "            connection = value.get_references()\n",
    "            node_a_ref = connection[0].split('.')\n",
    "            # Constraint references irrelevant primitive -----\n",
    "            if node_a_ref[0] not in node_ref_to_idx:\n",
    "                continue\n",
    "            node_a_idx = node_ref_to_idx[node_a_ref[0]]\n",
    "            # Add one hot encoding for where the constraint is applied for primitive\n",
    "            if len(node_a_ref) == 2:\n",
    "                    match node_a_ref[1]:\n",
    "                        case \"start\":\n",
    "                            edge_feature[0] = 1\n",
    "                        case \"center\":\n",
    "                            edge_feature[1] = 1\n",
    "                        case \"end\":\n",
    "                            edge_feature[2] = 1\n",
    "            else:\n",
    "                edge_feature[3] = 1\n",
    "            # If constraint only applies to 1 primitive\n",
    "            if len(connection) == 1:\n",
    "                # Multi graphs are not supported -----\n",
    "                if (node_a_idx, node_a_idx) in edge_exists:\n",
    "                    continue\n",
    "                # Add a self loop on node\n",
    "                edge_index[idx] = torch.tensor([node_a_idx, node_a_idx])\n",
    "                edge_exists[(node_a_idx, node_a_idx)] = True\n",
    "                # Save edge feature vector\n",
    "                edge_attr[idx] = edge_feature\n",
    "                idx += 1\n",
    "                continue\n",
    "            # If constraint applies to 2 primitives\n",
    "            node_b_ref = connection[1].split('.')\n",
    "            # Constraint references irrelevant primitive -----\n",
    "            if node_b_ref[0] not in node_ref_to_idx:\n",
    "                continue\n",
    "            node_b_idx = node_ref_to_idx[node_b_ref[0]]\n",
    "            # Add one hot encoding for where the constraint is applied for second primitive\n",
    "            if len(node_b_ref) == 2:\n",
    "                match node_b_ref[1]:\n",
    "                    case \"start\":\n",
    "                        edge_feature[4] = 1\n",
    "                    case \"center\":\n",
    "                        edge_feature[5] = 1\n",
    "                    case \"end\":\n",
    "                        edge_feature[6] = 1\n",
    "            else:\n",
    "                edge_feature[7] = 1\n",
    "            # Multi graphs are not supported -----\n",
    "            if (node_a_idx, node_b_idx) in edge_exists:\n",
    "                continue\n",
    "            # Add an edge between the 2 nodes\n",
    "            edge_index[idx] = torch.tensor([node_a_idx, node_b_idx])\n",
    "            edge_exists[(node_a_idx, node_b_idx)] = True\n",
    "            # Save edge feature vector\n",
    "            edge_attr[idx] = edge_feature\n",
    "            idx += 1\n",
    "        # Remove all unused adjacency info since there are a variable number of relevant constraints per sketch\n",
    "        edge_index = edge_index[:idx]\n",
    "        edge_attr = edge_attr[:idx]\n",
    "        return node_matrix, edge_index.T.contiguous(), edge_attr\n",
    "\n",
    "    @staticmethod\n",
    "    def graph_to_sketch(node_matrix, edge_index, edge_attr):\n",
    "        sketch = Sketch()\n",
    "        # Add entities\n",
    "        for idx in range(len(node_matrix)):\n",
    "            entity = node_matrix[idx]\n",
    "            match torch.argmax(entity[1:5]):\n",
    "                case 0:\n",
    "                    # Create Line\n",
    "                    id = str(idx + 1)\n",
    "                    isConstructible = bool(entity[0])\n",
    "                    pnt = entity[6:8]\n",
    "                    startParam = 0\n",
    "                    dir = (entity[8:10] - entity[6:8]) / torch.linalg.vector_norm(entity[8:10] - entity[6:8])\n",
    "                    endParam = torch.linalg.vector_norm(entity[8:10] - entity[6:8])\n",
    "                    line = Line(entityId = id,\n",
    "                                isConstruction = isConstructible, \n",
    "                                pntX = pnt[0], \n",
    "                                pntY = pnt[1], \n",
    "                                dirX = dir[0], \n",
    "                                dirY = dir[1], \n",
    "                                startParam = startParam, \n",
    "                                endParam = endParam\n",
    "                               );\n",
    "                    sketch.entities[id] = line\n",
    "                case 1:\n",
    "                    # Create Circle\n",
    "                    id = str(idx + 1)\n",
    "                    isConstructible = bool(entity[0])\n",
    "                    center = entity[10:12]\n",
    "                    radius = entity[12]\n",
    "                    circle = Circle(entityId = id, \n",
    "                                  isConstruction = isConstructible, \n",
    "                                  xCenter = center[0], \n",
    "                                  yCenter = center[1], \n",
    "                                  xDir = 1, \n",
    "                                  yDir = 0, \n",
    "                                  radius = radius, \n",
    "                                  clockwise = False\n",
    "                                 );\n",
    "                    sketch.entities[id] = circle\n",
    "                case 2: \n",
    "                    # Create Arc\n",
    "                    id = str(idx + 1)\n",
    "                    isConstructible = bool(entity[0])\n",
    "                    center = entity[13:15]\n",
    "                    radius = entity[15]\n",
    "                    startParam = entity[16] * (2*math.pi)\n",
    "                    endParam = entity[17] * (2*math.pi)\n",
    "                    arc = Arc(entityId = id, \n",
    "                              isConstruction = isConstructible, \n",
    "                              xCenter = center[0], \n",
    "                              yCenter = center[1], \n",
    "                              xDir = 1, \n",
    "                              yDir = 0,\n",
    "                              radius = radius, \n",
    "                              startParam = startParam,\n",
    "                              endParam = endParam, \n",
    "                              clockwise = False\n",
    "                             );\n",
    "                    sketch.entities[id] = arc\n",
    "                case 3:\n",
    "                    # Create Point\n",
    "                    id = str(idx + 1)\n",
    "                    isConstructible = bool(entity[0])\n",
    "                    x = entity[18]\n",
    "                    y = entity[19]\n",
    "                    point = Point(entityId = id, \n",
    "                                  isConstruction = isConstructible,\n",
    "                                  x = x,\n",
    "                                  y = y\n",
    "                                 );\n",
    "                    sketch.entities[id] = point\n",
    "        # Add constraints\n",
    "        for idx in range(len(edge_attr)):\n",
    "            constraint = edge_attr[idx]\n",
    "            identifier = \"c_\" + str(idx)\n",
    "            constraintType = ConstraintType.Coincident # Initial Value\n",
    "            param_ids = None\n",
    "            params = []\n",
    "            # Convert one hot encoding to constraint label\n",
    "            match torch.argmax(constraint[8:17]):\n",
    "                case 0:\n",
    "                    # Coincident\n",
    "                    constraintType = ConstraintType.Coincident\n",
    "                case 1:\n",
    "                    # Horizontal\n",
    "                    constraintType = ConstraintType.Horizontal\n",
    "                case 2:\n",
    "                    # Vertical\n",
    "                    constraintType = ConstraintType.Vertical\n",
    "                case 3:\n",
    "                    # Parallel\n",
    "                    constraintType = ConstraintType.Parallel\n",
    "                case 4:\n",
    "                    # Perpendicular\n",
    "                    constraintType = ConstraintType.Perpendicular\n",
    "                case 5:\n",
    "                    # Tangent\n",
    "                    constraintType = ConstraintType.Tangent\n",
    "                case 6:\n",
    "                    # Midpoint\n",
    "                    constraintType = ConstraintType.Midpoint\n",
    "                case 7:\n",
    "                    # Equal\n",
    "                    constraintType = ConstraintType.Equal\n",
    "                case _:\n",
    "                    # None\n",
    "                    continue\n",
    "            # Adjust reference parameter ids if necessary\n",
    "            if constraintType == ConstraintType.Midpoint:\n",
    "                param_ids = ['local0', 'local1']\n",
    "            else:\n",
    "                param_ids = ['localFirst', 'localSecond']\n",
    "            edge = edge_index.T[idx]\n",
    "            if torch.equal(edge[0], edge[1]):\n",
    "                # Constraint only applies to single entity\n",
    "                node_ref = str(edge[0])\n",
    "                match torch.argmax(constraint[0:4]):\n",
    "                    case 0:\n",
    "                        node_ref = node_ref + \".start\"\n",
    "                    case 1:\n",
    "                        node_ref = node_ref + \".center\"\n",
    "                    case 2:\n",
    "                        node_ref = node_ref + \".end\"\n",
    "                param1 = LocalReferenceParameter(param_ids[0], node_ref)\n",
    "                params.append(param1)\n",
    "            else:\n",
    "                # Constraint applies to 2 primitives\n",
    "                node_a_ref = str(edge[0])\n",
    "                match torch.argmax(constraint[0:4]):\n",
    "                    case 0:\n",
    "                        node_ref = node_a_ref + \".start\"\n",
    "                    case 1:\n",
    "                        node_ref = node_a_ref + \".center\"\n",
    "                    case 2:\n",
    "                        node_ref = node_a_ref + \".end\"\n",
    "                node_b_ref = str(edge[1])\n",
    "                match torch.argmax(constraint[4:8]):\n",
    "                    case 0:\n",
    "                        node_ref = node_b_ref + \".start\"\n",
    "                    case 1:\n",
    "                        node_ref = node_b_ref + \".center\"\n",
    "                    case 2:\n",
    "                        node_ref = node_b_ref + \".end\"\n",
    "                param1 = LocalReferenceParameter(param_ids[0], node_a_ref)\n",
    "                params.append(param1)\n",
    "                param2 = LocalReferenceParameter(param_ids[1], node_b_ref)\n",
    "                params.append(param2)\n",
    "            sketch.constraints[identifier] = Constraint(identifier, constraintType, params)\n",
    "        return sketch\n",
    "\n",
    "    @staticmethod\n",
    "    def preds_to_sketch(nodes, edges):\n",
    "        sketch = Sketch()\n",
    "        # Add entities\n",
    "        for idx in range(len(nodes)):\n",
    "            entity = nodes[idx]\n",
    "            match torch.argmax(entity[1:6]):\n",
    "                case 0:\n",
    "                    # Create Line\n",
    "                    id = str(idx + 1)\n",
    "                    isConstructible = bool(entity[0])\n",
    "                    pnt = entity[6:8]\n",
    "                    startParam = 0\n",
    "                    dir = (entity[8:10] - entity[6:8]) / torch.linalg.vector_norm(entity[8:10] - entity[6:8])\n",
    "                    endParam = torch.linalg.vector_norm(entity[8:10] - entity[6:8])\n",
    "                    line = Line(entityId = id,\n",
    "                                isConstruction = isConstructible, \n",
    "                                pntX = pnt[0], \n",
    "                                pntY = pnt[1], \n",
    "                                dirX = dir[0], \n",
    "                                dirY = dir[1], \n",
    "                                startParam = startParam, \n",
    "                                endParam = endParam\n",
    "                               );\n",
    "                    sketch.entities[id] = line\n",
    "                case 1:\n",
    "                    # Create Circle\n",
    "                    id = str(idx + 1)\n",
    "                    isConstructible = bool(entity[0])\n",
    "                    center = entity[10:12]\n",
    "                    radius = entity[12]\n",
    "                    circle = Circle(entityId = id, \n",
    "                                  isConstruction = isConstructible, \n",
    "                                  xCenter = center[0], \n",
    "                                  yCenter = center[1], \n",
    "                                  xDir = 1, \n",
    "                                  yDir = 0, \n",
    "                                  radius = radius, \n",
    "                                  clockwise = False\n",
    "                                 );\n",
    "                    sketch.entities[id] = circle\n",
    "                case 2: \n",
    "                    # Create Arc\n",
    "                    id = str(idx + 1)\n",
    "                    isConstructible = bool(entity[0])\n",
    "                    center = entity[13:15]\n",
    "                    radius = entity[15]\n",
    "                    startParam = entity[16] * (2*math.pi)\n",
    "                    endParam = entity[17] * (2*math.pi)\n",
    "                    arc = Arc(entityId = id, \n",
    "                              isConstruction = isConstructible, \n",
    "                              xCenter = center[0], \n",
    "                              yCenter = center[1], \n",
    "                              xDir = 1, \n",
    "                              yDir = 0,\n",
    "                              radius = radius, \n",
    "                              startParam = startParam,\n",
    "                              endParam = endParam, \n",
    "                              clockwise = False\n",
    "                             );\n",
    "                    sketch.entities[id] = arc\n",
    "                case 3:\n",
    "                    # Create Point\n",
    "                    id = str(idx + 1)\n",
    "                    isConstructible = bool(entity[0])\n",
    "                    x = entity[18]\n",
    "                    y = entity[19]\n",
    "                    point = Point(entityId = id, \n",
    "                                  isConstruction = isConstructible,\n",
    "                                  x = x,\n",
    "                                  y = y\n",
    "                                 );\n",
    "                    sketch.entities[id] = point\n",
    "                case _:\n",
    "                    continue\n",
    "\n",
    "        # Add constraints\n",
    "        idx = 0\n",
    "        for i in range(edges.size(0)):\n",
    "            for j in range(edges.size(1)):\n",
    "                constraint = edges[i][j]\n",
    "                identifier = \"c_\" + str(idx)\n",
    "                constraintType = ConstraintType.Coincident # Initial Value\n",
    "                param_ids = None\n",
    "                params = []\n",
    "                # Convert one hot encoding to constraint label\n",
    "                match torch.argmax(constraint[8:17]):\n",
    "                    case 0:\n",
    "                        # Coincident\n",
    "                        constraintType = ConstraintType.Coincident\n",
    "                    case 1:\n",
    "                        # Horizontal\n",
    "                        constraintType = ConstraintType.Horizontal\n",
    "                    case 2:\n",
    "                        # Vertical\n",
    "                        constraintType = ConstraintType.Vertical\n",
    "                    case 3:\n",
    "                        # Parallel\n",
    "                        constraintType = ConstraintType.Parallel\n",
    "                    case 4:\n",
    "                        # Perpendicular\n",
    "                        constraintType = ConstraintType.Perpendicular\n",
    "                    case 5:\n",
    "                        # Tangent\n",
    "                        constraintType = ConstraintType.Tangent\n",
    "                    case 6:\n",
    "                        # Midpoint\n",
    "                        constraintType = ConstraintType.Midpoint\n",
    "                    case 7:\n",
    "                        # Equal\n",
    "                        constraintType = ConstraintType.Equal\n",
    "                    case _:\n",
    "                        # None\n",
    "                        continue\n",
    "                # Adjust reference parameter ids if necessary\n",
    "                if constraintType == ConstraintType.Midpoint:\n",
    "                    param_ids = ['local0', 'local1']\n",
    "                else:\n",
    "                    param_ids = ['localFirst', 'localSecond']\n",
    "                edge = torch.Tensor([i, j])\n",
    "                if torch.equal(edge[0], edge[1]):\n",
    "                    # Constraint only applies to single entity\n",
    "                    node_ref = str(edge[0])\n",
    "                    match torch.argmax(constraint[0:4]):\n",
    "                        case 0:\n",
    "                            node_ref = node_ref + \".start\"\n",
    "                        case 1:\n",
    "                            node_ref = node_ref + \".center\"\n",
    "                        case 2:\n",
    "                            node_ref = node_ref + \".end\"\n",
    "                    param1 = LocalReferenceParameter(param_ids[0], node_ref)\n",
    "                    params.append(param1)\n",
    "                else:\n",
    "                    # Constraint applies to 2 primitives\n",
    "                    node_a_ref = str(edge[0])\n",
    "                    match torch.argmax(constraint[0:4]):\n",
    "                        case 0:\n",
    "                            node_ref = node_a_ref + \".start\"\n",
    "                        case 1:\n",
    "                            node_ref = node_a_ref + \".center\"\n",
    "                        case 2:\n",
    "                            node_ref = node_a_ref + \".end\"\n",
    "                    node_b_ref = str(edge[1])\n",
    "                    match torch.argmax(constraint[4:8]):\n",
    "                        case 0:\n",
    "                            node_ref = node_b_ref + \".start\"\n",
    "                        case 1:\n",
    "                            node_ref = node_b_ref + \".center\"\n",
    "                        case 2:\n",
    "                            node_ref = node_b_ref + \".end\"\n",
    "                    param1 = LocalReferenceParameter(param_ids[0], node_a_ref)\n",
    "                    params.append(param1)\n",
    "                    param2 = LocalReferenceParameter(param_ids[1], node_b_ref)\n",
    "                    params.append(param2)\n",
    "                sketch.constraints[identifier] = Constraint(identifier, constraintType, params)\n",
    "                idx = idx + 1\n",
    "        return sketch\n",
    "    \n",
    "    @staticmethod\n",
    "    def params_mask(nodes):\n",
    "        mask = torch.zeros(size = (MAX_NUM_PRIMITIVES, NODE_FEATURE_DIMENSION - NUM_PRIMITIVE_TYPES - 1))\n",
    "        i = 0\n",
    "        for node in nodes:\n",
    "            match torch.argmax(node[1:6]):\n",
    "                case 0:\n",
    "                    # Line\n",
    "                    mask[i][0:4] = 1\n",
    "                case 1:\n",
    "                    # Circle\n",
    "                    mask[i][4:7] = 1\n",
    "                case 2:\n",
    "                    # Arc\n",
    "                    mask[i][7:12] = 1\n",
    "                case 3:\n",
    "                    # Point\n",
    "                    mask[i][12:] = 1\n",
    "            i = i + 1\n",
    "        return mask\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_graph(node_matrix, adjacency_list):\n",
    "        # Helper variables\n",
    "        num_nodes = len(node_matrix)\n",
    "        node_out_degrees = pygutils.degree(adjacency_list.long()[0], num_nodes)\n",
    "        # Generate permutation indices to sort graph\n",
    "        indices = range(num_nodes)\n",
    "        node_permutation_indices = sorted(  indices, key = lambda idx: (  node_matrix[idx].tolist() + [node_out_degrees[idx]]  )  )\n",
    "        # return sorted node feature matrix and adjacency list\n",
    "        sorted_node_matrix = node_matrix[node_permutation_indices]\n",
    "        node_oldidx_to_newidx = [node_permutation_indices.index(value) for value in range(len(node_permutation_indices))]\n",
    "        updated_adjacency_list = torch.Tensor(node_oldidx_to_newidx)[adjacency_list.long()]\n",
    "        return sorted_node_matrix, updated_adjacency_list\n",
    "    \n",
    "    def len(self):\n",
    "        # The minus two is there because pre_transform.pt and pre_filter.pt are also included in processed_file_names\n",
    "        return 4008985\n",
    "    \n",
    "    def get(self, idx):\n",
    "        # For whatever reason there is a limit of ~3 million files/sub directories per directory on my university's nfs share, \n",
    "        # so ~4.4 million data files are partitioned into ~88 subdirectories containing atmost 50,000 data files each\n",
    "        \n",
    "        return torch.load(os.path.join(self.processed_dir, f'{int(idx / 50000)}/data_{idx}.pt'))\n",
    "        \n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SketchDataset(root = \"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m [ transform(torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(idx \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m50000\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/data_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)))  \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m) ]\n",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m [ transform(torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(idx \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m50000\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/data_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)))  \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m) ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "# data = [ transform(torch.load(os.path.join(self.processed_dir, f'{int(idx / 50000)}/data_{idx}.pt')))  for idx in range(1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import GVAE\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Graphs in total:  4461654\n",
      "Number of Graphs for training:  4015489\n",
      "Number of Graphs for validation:  147235\n",
      "Number of Graphs for testing:  298930\n"
     ]
    }
   ],
   "source": [
    "dataset = SketchDataset(root=\"data/\")\n",
    "\n",
    "generator = torch.Generator().manual_seed(4)\n",
    "train_set, validate_set, test_set = random_split(dataset = dataset, lengths = [0.9, 0.033, 0.067], generator = generator)\n",
    "\n",
    "print(\"Number of Graphs in total: \", dataset.len())\n",
    "print(\"Number of Graphs for training: \", len(train_set))\n",
    "print(\"Number of Graphs for validation: \", len(validate_set))\n",
    "print(\"Number of Graphs for testing: \", len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_set, batch_size = batch_size, persistent_workers = True, num_workers = 8, pin_memory = True)\n",
    "validate_loader = DataLoader(dataset = validate_set, batch_size = batch_size, persistent_workers = True, num_workers = 8, pin_memory = True)\n",
    "test_loader = DataLoader(dataset = test_set, batch_size = batch_size, persistent_workers = True, num_workers = 8, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n"
     ]
    }
   ],
   "source": [
    "for batch_index, (nodes, edges, node_params_mask) in enumerate(validate_loader):\n",
    "    nodes = nodes.to(device)\n",
    "    edges = edges.to(device)\n",
    "    node_params_mask = node_params_mask.to(device)\n",
    "    print(batch_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('SketchGraphs/')\n",
    "# Load SketchGraphs sequence data dictionary\n",
    "seq_data = flat_array.load_dictionary_flat('../data/raw/sg_all.npy')\n",
    "sequences = seq_data[\"sequences\"]\n",
    "seq = sequences[1710157]\n",
    "sketch = datalib.sketch_from_sequence(seq)\n",
    "\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NodeOp(label=<EntityType.External: 7>, parameters={})\n",
      "NodeOp(label=<EntityType.Point: 0>, parameters={'isConstruction': False, 'x': 0.0, 'y': 0.0})\n",
      "EdgeOp(label=<ConstraintType.Projected: 1>, references=(1, 0), parameters={})\n",
      "NodeOp(label=<EntityType.Line: 1>, parameters={'isConstruction': False, 'dirX': 1.0, 'dirY': 0.0, 'pntX': 0.00921805202960968, 'pntY': 0.0, 'startParam': -0.00921805202960968, 'endParam': 0.00921805202960968})\n",
      "NodeOp(label=<SubnodeType.SN_Start: 101>, parameters={})\n",
      "EdgeOp(label=<ConstraintType.Subnode: 101>, references=(3, 2), parameters={})\n",
      "EdgeOp(label=<ConstraintType.Coincident: 0>, references=(3, 1), parameters={})\n",
      "NodeOp(label=<SubnodeType.SN_End: 102>, parameters={})\n",
      "EdgeOp(label=<ConstraintType.Subnode: 101>, references=(4, 2), parameters={})\n",
      "NodeOp(label=<EntityType.Line: 1>, parameters={'isConstruction': False, 'dirX': 1.0, 'dirY': 0.0, 'pntX': 0.00921805202960968, 'pntY': -0.01657174527645111, 'startParam': -0.00921805202960968, 'endParam': 0.00921805202960968})\n",
      "EdgeOp(label=<ConstraintType.Parallel: 5>, references=(5, 2), parameters={})\n",
      "EdgeOp(label=<ConstraintType.Horizontal: 4>, references=(5,), parameters={})\n",
      "NodeOp(label=<SubnodeType.SN_Start: 101>, parameters={})\n",
      "EdgeOp(label=<ConstraintType.Subnode: 101>, references=(6, 5), parameters={})\n",
      "NodeOp(label=<SubnodeType.SN_End: 102>, parameters={})\n",
      "EdgeOp(label=<ConstraintType.Subnode: 101>, references=(7, 5), parameters={})\n",
      "NodeOp(label=<EntityType.Line: 1>, parameters={'isConstruction': False, 'dirX': 0.0, 'dirY': -1.0, 'pntX': 0.0, 'pntY': -0.008285872638225555, 'startParam': -0.008285872638225555, 'endParam': 0.008285872638225555})\n",
      "EdgeOp(label=<ConstraintType.Perpendicular: 9>, references=(8, 5), parameters={})\n",
      "NodeOp(label=<SubnodeType.SN_Start: 101>, parameters={})\n",
      "EdgeOp(label=<ConstraintType.Subnode: 101>, references=(9, 8), parameters={})\n",
      "EdgeOp(label=<ConstraintType.Coincident: 0>, references=(9, 3), parameters={})\n",
      "NodeOp(label=<SubnodeType.SN_End: 102>, parameters={})\n",
      "EdgeOp(label=<ConstraintType.Subnode: 101>, references=(10, 8), parameters={})\n",
      "EdgeOp(label=<ConstraintType.Coincident: 0>, references=(10, 6), parameters={})\n",
      "NodeOp(label=<EntityType.Line: 1>, parameters={'isConstruction': False, 'dirX': 0.0, 'dirY': -1.0, 'pntX': 0.01843610405921936, 'pntY': -0.008285872638225555, 'startParam': -0.008285872638225555, 'endParam': 0.008285872638225555})\n",
      "EdgeOp(label=<ConstraintType.Parallel: 5>, references=(11, 8), parameters={})\n",
      "NodeOp(label=<SubnodeType.SN_Start: 101>, parameters={})\n",
      "EdgeOp(label=<ConstraintType.Subnode: 101>, references=(12, 11), parameters={})\n",
      "EdgeOp(label=<ConstraintType.Coincident: 0>, references=(12, 4), parameters={})\n",
      "NodeOp(label=<SubnodeType.SN_End: 102>, parameters={})\n",
      "EdgeOp(label=<ConstraintType.Subnode: 101>, references=(13, 11), parameters={})\n",
      "EdgeOp(label=<ConstraintType.Coincident: 0>, references=(13, 7), parameters={})\n",
      "NodeOp(label=<EntityType.Point: 0>, parameters={'isConstruction': False, 'x': nan, 'y': nan})\n",
      "NodeOp(label=<EntityType.Line: 1>, parameters={'isConstruction': False, 'dirX': 1.0, 'dirY': 0.0, 'pntX': nan, 'pntY': nan, 'startParam': -0.00921805202960968, 'endParam': 0.00921805202960968})\n",
      "NodeOp(label=<SubnodeType.SN_Start: 101>, parameters={})\n",
      "EdgeOp(label=<ConstraintType.Subnode: 101>, references=(16, 15), parameters={})\n",
      "EdgeOp(label=<ConstraintType.Coincident: 0>, references=(16, 14), parameters={})\n",
      "NodeOp(label=<SubnodeType.SN_End: 102>, parameters={})\n",
      "EdgeOp(label=<ConstraintType.Subnode: 101>, references=(17, 15), parameters={})\n",
      "NodeOp(label=<EntityType.Line: 1>, parameters={'isConstruction': False, 'dirX': 1.0, 'dirY': 0.0, 'pntX': nan, 'pntY': nan, 'startParam': -0.00921805202960968, 'endParam': 0.00921805202960968})\n",
      "EdgeOp(label=<ConstraintType.Parallel: 5>, references=(18, 15), parameters={})\n",
      "EdgeOp(label=<ConstraintType.Horizontal: 4>, references=(18,), parameters={})\n",
      "NodeOp(label=<SubnodeType.SN_Start: 101>, parameters={})\n",
      "EdgeOp(label=<ConstraintType.Subnode: 101>, references=(19, 18), parameters={})\n",
      "NodeOp(label=<SubnodeType.SN_End: 102>, parameters={})\n",
      "EdgeOp(label=<ConstraintType.Subnode: 101>, references=(20, 18), parameters={})\n",
      "NodeOp(label=<EntityType.Line: 1>, parameters={'isConstruction': False, 'dirX': 0.0, 'dirY': -1.0, 'pntX': nan, 'pntY': nan, 'startParam': -0.008285872638225555, 'endParam': 0.008285872638225555})\n",
      "EdgeOp(label=<ConstraintType.Perpendicular: 9>, references=(21, 18), parameters={})\n",
      "NodeOp(label=<SubnodeType.SN_Start: 101>, parameters={})\n",
      "EdgeOp(label=<ConstraintType.Subnode: 101>, references=(22, 21), parameters={})\n",
      "EdgeOp(label=<ConstraintType.Coincident: 0>, references=(22, 16), parameters={})\n",
      "NodeOp(label=<SubnodeType.SN_End: 102>, parameters={})\n",
      "EdgeOp(label=<ConstraintType.Subnode: 101>, references=(23, 21), parameters={})\n",
      "EdgeOp(label=<ConstraintType.Coincident: 0>, references=(23, 19), parameters={})\n",
      "NodeOp(label=<EntityType.Line: 1>, parameters={'isConstruction': False, 'dirX': 0.0, 'dirY': -1.0, 'pntX': nan, 'pntY': nan, 'startParam': -0.008285872638225555, 'endParam': 0.008285872638225555})\n",
      "EdgeOp(label=<ConstraintType.Parallel: 5>, references=(24, 21), parameters={})\n",
      "NodeOp(label=<SubnodeType.SN_Start: 101>, parameters={})\n",
      "EdgeOp(label=<ConstraintType.Subnode: 101>, references=(25, 24), parameters={})\n",
      "EdgeOp(label=<ConstraintType.Coincident: 0>, references=(25, 17), parameters={})\n",
      "NodeOp(label=<SubnodeType.SN_End: 102>, parameters={})\n",
      "EdgeOp(label=<ConstraintType.Subnode: 101>, references=(26, 24), parameters={})\n",
      "EdgeOp(label=<ConstraintType.Coincident: 0>, references=(26, 20), parameters={})\n",
      "NodeOp(label=<EntityType.Stop: 8>, parameters={})\n",
      "Point [1] ((0.0, 0.0))\n",
      "Line [2] p(0.00921805202960968, 0.0) d(1.0, 0.0) param(-0.00921805202960968, 0.00921805202960968)\n",
      "Line [5] p(0.00921805202960968, -0.01657174527645111) d(1.0, 0.0) param(-0.00921805202960968, 0.00921805202960968)\n",
      "Line [8] p(0.0, -0.008285872638225555) d(0.0, -1.0) param(-0.008285872638225555, 0.008285872638225555)\n",
      "Line [11] p(0.01843610405921936, -0.008285872638225555) d(0.0, -1.0) param(-0.008285872638225555, 0.008285872638225555)\n",
      "Point [14] ((nan, nan))\n",
      "Line [15] p(nan, nan) d(1.0, 0.0) param(-0.00921805202960968, 0.00921805202960968)\n",
      "Line [18] p(nan, nan) d(1.0, 0.0) param(-0.00921805202960968, 0.00921805202960968)\n",
      "Line [21] p(nan, nan) d(0.0, -1.0) param(-0.008285872638225555, 0.008285872638225555)\n",
      "Line [24] p(nan, nan) d(0.0, -1.0) param(-0.008285872638225555, 0.008285872638225555)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
